<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"></head><body>"[Front cover]," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. c1-c1.<br>doi: 10.1109/MSR.2010.5463363<br>Abstract: Presents the front cover or splash screen of the proceedings.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463363&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463363&amp;isnumber=5463276</a><br><br>"Hub page," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 1-1.<br>doi: 10.1109/MSR.2010.5463351<br>Abstract:
 The paper deals with the following topics: data security; data mining; 
software engineering; Java systems; open source software; and database 
management systems.<br> keywords: {Java;data mining;database management 
systems;public domain software;security of data;software 
engineering;Java systems;data mining;data security;database management 
systems;open source software;software engineering},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463351&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463351&amp;isnumber=5463276</a><br><br>"Session list," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 1-1.<br>doi: 10.1109/MSR.2010.5463352<br>Abstract: Provides a schedule of conference events and a listing of which papers were presented in each session.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463352&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463352&amp;isnumber=5463276</a><br><br>"MSR 2010 table of contents," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 1-4.<br>doi: 10.1109/MSR.2010.5463353<br>Abstract: Presents the table of contents of the proceedings.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463353&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463353&amp;isnumber=5463276</a><br><br>"MSR 2010 brief author index," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 1-3.<br>doi: 10.1109/MSR.2010.5463354<br>Abstract: Presents an index of the authors whose papers are published in the conference.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463354&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463354&amp;isnumber=5463276</a><br><br>"MSR 2010 detailed author index," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 1-26.<br>doi: 10.1109/MSR.2010.5463355<br>Abstract: Presents an index of the authors whose papers are published in the conference.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463355&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463355&amp;isnumber=5463276</a><br><br>A. Mockus, J. Whitehead, T. Zimmermann and A. Hindle, "Welcome from the chairs," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, South Africa, 2010, pp. 1-2.<br>doi: 10.1109/MSR.2010.5463356<br>Abstract:
 Welcome to MSR 2010, the Seventh IEEE Working Conference on Mining 
Software Repositories, held May 2–3 in Cape Town, South Africa, and 
co-located with the 2010 ACM/IEEE International Conference on Software 
Engineering (ICSE 2010).<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463356&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463356&amp;isnumber=5463276</a><br><br>"MSR 2010 Organizing Committee," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 1-1.<br>doi: 10.1109/MSR.2010.5463357<br>Abstract: Provides a listing of current committee members.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463357&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463357&amp;isnumber=5463276</a><br><br>"MSR 2010 Program Committee," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 1-1.<br>doi: 10.1109/MSR.2010.5463358<br>Abstract: Provides a listing of current committee members.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463358&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463358&amp;isnumber=5463276</a><br><br>"MSR 2010 challenge Committee," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 1-1.<br>doi: 10.1109/MSR.2010.5463359<br>Abstract: Provides a listing of current committee members.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463359&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463359&amp;isnumber=5463276</a><br><br>J. Herbsleb, "MSR: Mining for scientific results?," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 1-1.<br>doi: 10.1109/MSR.2010.5463360<br>Abstract:
 MSR has established an impressive presence in the intellectual 
landscape of software engineering in its seven short years. Insights 
accumulate as methods continue to mature. Results of practical 
significance attract increasing numbers of papers and attendees each 
year. Yet I will argue that MSR is insufficiently ambitious. The 
community should be seeking enduring scientific results as well as 
immediate impact. I will argue that progress in three directions will 
help move MSR toward this possible future. First, while Â¿black boxÂ¿ 
prediction models can be quite useful, the community should be driving 
toward development of a body of theory that sheds light on the 
underlying phenomena. Second, the community should not be content just 
to analyze data that happens to exist, but should tackle the problem of 
defining the data that would be scientifically useful, and follow up by 
designing and deploying environments that automatically collect it. 
Finally, the community should push beyond software artifacts, 
recognizing that many forms of technical design and production work 
share fundamental characteristics. We should seek to join forces with 
other research communities that are analyzing behavioral traces in areas
 such as social networking, blogs, and online communities. As successful
 as MSR has been, it has only scratched the surface of its potential to 
forge a science of socio-technical behavior.<br> keywords: {data 
mining;software engineering;MSR;behavioral traces;black box 
prediction;blogs;intellectual landscape;mining for scientific 
results;online communities;social networking;socio technical 
behavior;software artifacts;software engineering;technical 
design;Biographies;Blogs;Character recognition;Collaborative 
software;Computer science;Data analysis;Predictive 
models;Production;Social network services;Software engineering},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463360&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463360&amp;isnumber=5463276</a><br><br>M. Lanza, "The visual terminator," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 1-1.<br>doi: 10.1109/MSR.2010.5463361<br>Abstract:
 Summary form only given. In this talk, machines take over the world in 
the near future, directed by the artificially intelligent computer 
Vinet. With its sole mission to completely annihilate developers, it 
creates emacs assassins called Terminators that carry the outward 
appearance of software engineers. The software visualization resistance 
is there to defeat them and free developers. With a human victory 
imminent, the machines' only choice is to send a Terminator back in time
 to kill Mayfair and Bertin, preventing the resistance from ever being 
founded. With the fate of software visualization at stake, the 
resistance sends a keynote speaker back to ensure its own existence.<br>
 keywords: {artificial intelligence;data visualisation;artificial 
intelligence;emacs assassins;software visualization resistance;visual 
terminator;Artificial intelligence;Biographies;Education;Humans;Immune 
system;Informatics;Machine intelligence;Software engineering;Software 
maintenance;Visualization},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463361&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463361&amp;isnumber=5463276</a><br><br>N. Juristo and S. Vegas, "Using differences among replications of software engineering experiments to gain knowledge," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 1-1.<br>doi: 10.1109/MSR.2010.5463362<br>Abstract:
 In no science or engineering discipline does it make sense to speak of 
isolated experiments. The results of a single experiment cannot be 
viewed as representative of the underlying reality. The concept of 
experiment is closely related to replication. Experiment replication is 
the repetition of an experiment to double-check its results. Multiple 
replications of an experiment increase the credibility of its results. 
Software engineering has tried its hand at the identical repetition of 
experiments in the way of the natural sciences (physics, chemistry, 
etc.). After numerous attempts over the years, excepting experiments 
repeated by the same researchers at the same site, no exact replications
 have yet been achieved. One key reason for this is the complexity of 
the software development setting. This complexity prevents the many 
experimental conditions from being reproduced identically. This paper 
reports research into whether non-exact replications can be of any use. 
We propose a process that allows researchers to generate new knowledge 
when running non-exact replications. To illustrate the advantages of the
 proposed process, two different replications of an experiment are 
shown.<br> keywords: {software engineering;experiment 
replications;natural sciences;software development complexity;software 
engineering;Biographies;Chemistry;Knowledge 
engineering;Physics;Programming;Software engineering;Software 
measurement;Software systems},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463362&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463362&amp;isnumber=5463276</a><br><br>A. Lamkanfi, S. Demeyer, E. Giger and B. Goethals, "Predicting the severity of a reported bug," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 1-10.<br>doi: 10.1109/MSR.2010.5463284<br>Abstract:
 The severity of a reported bug is a critical factor in deciding how 
soon it needs to be fixed. Unfortunately, while clear guidelines exist 
on how to assign the severity of a bug, it remains an inherent manual 
process left to the person reporting the bug. In this paper we 
investigate whether we can accurately predict the severity of a reported
 bug by analyzing its textual description using text mining algorithms. 
Based on three cases drawn from the open-source community (Mozilla, 
Eclipse and GNOME), we conclude that given a training set of sufficient 
size (approximately 500 reports per severity), it is possible to predict
 the severity with a reasonable accuracy (both precision and recall vary
 between 0.65-0.75 with Mozilla and Eclipse; 0.70-0.85 in the case of 
GNOME).<br> keywords: {data mining;program debugging;public domain 
software;Eclipse;GNOME;Mozilla;open source community;reported 
bug;severity prediction;text mining algorithms;textual 
description;Algorithm design and analysis;Computer architecture;Computer
 bugs;Computer crashes;Guidelines;Programming;Seals;Software 
debugging;Software systems;Text mining},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463284&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463284&amp;isnumber=5463276</a><br><br>M. Gegick, P. Rotella and T. Xie, "Identifying security bug reports via text mining: An industrial case study," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 11-20.<br>doi: 10.1109/MSR.2010.5463340<br>Abstract:
 A bug-tracking system such as Bugzilla contains bug reports (BRs) 
collected from various sources such as development teams, testing teams,
 and end users. When bug reporters submit bug reports to a bug-tracking 
system, the bug reporters need to label the bug reports as security bug 
reports (SBRs) or not, to indicate whether the involved bugs are 
security problems. These SBRs generally deserve higher priority in bug 
fixing than not-security bug reports (NSBRs). However, in the 
bug-reporting process, bug reporters often mislabel SBRs as NSBRs partly
 due to lack of security domain knowledge. This mislabeling could cause 
serious damage to software-system stakeholders due to the induced delay 
of identifying and fixing the involved security bugs. To address this 
important issue, we developed a new approach that applies text mining on
 natural-language descriptions of BRs to train a statistical model on 
already manually-labeled BRs to identify SBRs that are 
manually-mislabeled as NSBRs. Security engineers can use the model to 
automate the classification of BRs from large bug databases to reduce 
the time that they spend on searching for SBRs. We evaluated the model's
 predictions on a large Cisco software system with over ten million 
source lines of code. Among a sample of BRs that Cisco bug reporters 
manually labeled as NSBRs in bug reporting, our model successfully 
classified a high percentage (78%) of the SBRs as verified by Cisco 
security engineers, and predicted their classification as SBRs with a 
probability of at least 0.98.<br> keywords: {data mining;program 
debugging;security of data;statistical analysis;text 
analysis;Bugzilla;Cisco security engineers;Cisco software 
system;bug-tracking system;development teams;end users;industrial case 
study;natural language descriptions;security bug reports;software system
 stakeholders;statistical model;testing teams;text mining;Computer 
bugs;Data engineering;Data security;Databases;Delay;Mining 
industry;Predictive models;Software systems;System testing;Text mining},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463340&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463340&amp;isnumber=5463276</a><br><br>A.
 Nugroho, M. R. V. Chaudron and E. Arisholm, "Assessing UML design 
metrics for predicting fault-prone classes in a Java system," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 21-30.<br>doi: 10.1109/MSR.2010.5463285<br>Abstract:
 Identifying and fixing software problems before implementation are 
believed to be much cheaper than after implementation. Hence, it follows
 that predicting fault-proneness of software modules based on early 
software artifacts like software design is beneficial as it allows 
software engineers to perform early predictions to anticipate and avoid 
faults early enough. Taking this motivation into consideration, in this 
paper we evaluate the usefulness of UML design metrics to predict 
fault-proneness of Java classes. We use historical data of a significant
 industrial Java system to build and validate a UML-based prediction 
model. Based on the case study we have found that level of detail of 
messages and import coupling-both measured from sequence diagrams, are 
significant predictors of class fault-proneness. We also learn that the 
prediction model built exclusively using the UML design metrics 
demonstrates a better accuracy than the one built exclusively using code
 metrics.<br> keywords: {Java;Unified Modeling Language;software fault 
tolerance;software metrics;Java system;UML design metrics;Unified 
Modeling Language;code metrics;fault-prone class prediction;import 
coupling;message detail level;sequence diagrams;software design;software
 modules;Accuracy;Java;Laboratories;Object oriented modeling;Predictive 
models;Software design;Software measurement;Software 
performance;Software quality;Unified modeling 
language;Classification;Defect;Fault;Logistic 
Regression;Prediction;Quality},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463285&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463285&amp;isnumber=5463276</a><br><br>M. D'Ambros, M. Lanza and R. Robbes, "An extensive comparison of bug prediction approaches," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 31-41.<br>doi: 10.1109/MSR.2010.5463279<br>Abstract:
 Reliably predicting software defects is one of software engineering's 
holy grails. Researchers have devised and implemented a plethora of bug 
prediction approaches varying in terms of accuracy, complexity and the 
input data they require. However, the absence of an established 
benchmark makes it hard, if not impossible, to compare approaches. We 
present a benchmark for defect prediction, in the form of a publicly 
available data set consisting of several software systems, and provide 
an extensive comparison of the explanative and predictive power of 
well-known bug prediction approaches, together with novel approaches we 
devised. Based on the results, we discuss the performance and stability 
of the approaches with respect to our benchmark and deduce a number of 
insights on bug prediction models.<br> keywords: {program 
debugging;resource allocation;software engineering;bug prediction 
approaches;resource allocation problem;software defects;software 
engineering;Computer bugs;Computer science;Entropy;Informatics;Open 
source software;Power system modeling;Predictive models;Software 
engineering;Software systems;Stability},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463279&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463279&amp;isnumber=5463276</a><br><br>S. McIntosh, B. Adams and A. E. Hassan, "The evolution of ANT build systems," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 42-51.<br>doi: 10.1109/MSR.2010.5463341<br>Abstract:
 Build systems are responsible for transforming static source code 
artifacts into executable software. While build systems play such a 
crucial role in software development and maintenance, they have been 
largely ignored by software evolution researchers. With a firm 
understanding of build system aging processes, project managers could 
allocate personnel and resources to build system maintenance tasks more 
effectively, reducing the build maintenance overhead on regular 
development activities. In this paper, we study the evolution of ANT 
build systems from two perspectives: (1) a static perspective, where we 
examine the build system specifications using software metrics adopted 
from the source code domain; and (2) a dynamic perspective where 
representative sample build runs are conducted and their output logs are
 analyzed. Case studies of four open source ANT build systems with a 
combined history of 152 releases show that not only do ANT build systems
 evolve, but also that they need to react in an agile manner to changes 
in the source code.<br> keywords: {software maintenance;software 
metrics;source coding;ANT build systems;build system aging 
processes;executable software;software development;software evolution 
researchers;software maintenance;software metrics;static source code 
artifacts;Aging;History;Open source software;Pattern 
analysis;Personnel;Programming;Project management;Software 
maintenance;Software metrics;Software systems},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463341&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463341&amp;isnumber=5463276</a><br><br>L.
 Nussbaum and S. Zacchiroli, "The Ultimate Debian Database: 
Consolidating bazaar metadata for Quality Assurance and data mining," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 52-61.<br>doi: 10.1109/MSR.2010.5463277<br>Abstract:
 FLOSS distributions like RedHat and Ubuntu require a lot more complex 
infrastructures than most other FLOSS projects. In the case of 
community-driven distributions like Debian, the development of such an 
infrastructure is often not very organized, leading to new data sources 
being added in an impromptu manner while hackers set up new services 
that gain acceptance in the community. Mixing and matching data is then 
harder than should be, albeit being badly needed for Quality Assurance 
and data mining. Massive refactoring and integration is not a viable 
solution either, due to the constraints imposed by the bazaar 
development model. This paper presents the Ultimate Debian Database 
(UDD), which is the countermeasure adopted by the Debian project to the 
above Â¿data hellÂ¿. UDD gathers data from various data sources into a 
single, central SQL database, turning Quality Assurance needs that could
 not be easily implemented before into simple SQL queries. The paper 
also discusses the customs that have contributed to the data hell, the 
lessons learnt while designing UDD, and its applications and 
potentialities for data mining on FLOSS distributions.<br> keywords: 
{SQL;data mining;marketing data processing;meta data;public domain 
software;quality assurance;Debian project;FLOSS distribution;FLOSS 
project;RedHat;SQL database;SQL query;Ubuntu;bazaar development 
model;bazaar metadata;community driven distribution;data mining;open 
source software;quality assurance;Computer bugs;Computer hacking;Data 
mining;Data warehouses;Databases;Open source software;Packaging;Quality 
assurance;Standardization;Turning;data mining;data 
warehouse;distribution;open source;quality assurance},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463277&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463277&amp;isnumber=5463276</a><br><br>A.
 Bachmann and A. Bernstein, "When process data quality affects the 
number of bugs: Correlations in software engineering datasets," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 62-71.<br>doi: 10.1109/MSR.2010.5463286<br>Abstract:
 Software engineering process information extracted from version control
 systems and bug tracking databases are widely used in empirical 
software engineering. In prior work, we showed that these data are 
plagued by quality deficiencies, which vary in its characteristics 
across projects. In addition, we showed that those deficiencies in the 
form of bias do impact the results of studies in empirical software 
engineering. While these findings affect software engineering 
researchers the impact on practitioners has not yet been substantiated. 
In this paper we, therefore, explore (i) if the process data quality and
 characteristics have an influence on the bug fixing process and (ii) if
 the process quality as measured by the process data has an influence on
 the product (i.e., software) quality. Specifically, we analyze six Open
 Source as well as two Closed Source projects and show that process data
 quality and characteristics have an impact on the bug fixing process: 
the high rate of empty commit messages in Eclipse, for example, 
correlates with the bug report quality. We also show that the product 
quality - measured by number of bugs reported - is affected by process 
data quality measures. These findings have the potential to prompt 
practitioners to increase the quality of their software process and its 
associated data quality.<br> keywords: {configuration management;program
 debugging;public domain software;software quality;Eclipse;bug fixing 
process;bug report quality;bug tracking databases;closed source 
projects;correlation;information extraction;open source projects;process
 data quality;software engineering datasets;version control 
systems;Cascading style sheets;Computer bugs;Data 
engineering;Informatics;Open source software;Prediction 
algorithms;Software engineering;Software measurement;Software 
quality;Software testing;case study;correlation;mining software 
repositories;process quality;product quality},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463286&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463286&amp;isnumber=5463276</a><br><br>F. Rahman, C. Bird and P. Devanbu, "Clones: What is that smell?," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 72-81.<br>doi: 10.1109/MSR.2010.5463343<br>Abstract:
 Clones are generally considered bad programming practice in software 
engineering folklore. They are identified as a bad smell and a major 
contributor to project maintenance difficulties. Clones inherently cause
 code bloat, thus increasing project size and maintenance costs. In this
 work, we try to validate the conventional wisdom empirically to see 
whether cloning makes code more defect prone. This paper analyses 
relationship between cloning and defect proneness. We find that, first, 
the great majority of bugs are not significantly associated with clones.
 Second, we find that clones may be less defect prone than non-cloned 
code. Finally, we find little evidence that clones with more copies are 
actually more error prone. Our findings do not support the claim that 
clones are really a Â¿bad smellÂ¿. Perhaps we can clone, and breathe 
easy, at the same time.<br> keywords: {program debugging;software 
maintenance;bugs;clones;code bloat;defect proneness;project 
maintenance;software engineering;Birds;Cloning;Computer bugs;Computer 
science;Costs;Productivity;Programming;Software engineering;Software 
maintenance;Taxonomy;empirical software engineering;software 
clone;software evolution;software maintenance},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463343&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463343&amp;isnumber=5463276</a><br><br>A. Hindle, I. Herraiz, E. Shihab and Zhen Ming Jiang, "Mining Challenge 2010: FreeBSD, GNOME Desktop and Debian/Ubuntu," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 82-85.<br>doi: 10.1109/MSR.2010.5463350<br>Abstract:
 In a young field, such as Mining Software Repositories (MSR), there is 
always a call for benchmarks so that researchers can compare their 
results against others. Thus in order to explore and discover the 
breadth of MSR research, the MSR community has banded together behind 
the MSR Mining Challenge. The mining challenge allows researchers to 
demonstrate current working techniques against a common set of 
repositories or datasets with the express purpose of mining interesting 
facts from these datasets and then comparing these results against the 
results from other researchers. This year, 2010, the MSR Mining 
Challenge has expanded the size of its underlying dataset to include the
 version control, bug tracker, and mailinglists of the following 
software distributions and projects: FreeBSD, GNOME Desktop and 
Debian/Ubuntu. Researchers are asked to look beyond the boundaries of a 
project and investigate the relationship between the evolution of 
various programs contained within these software ecosystems. 9 general 
challenge submissions were submitted, 6 were accepted with a 66% 
acceptance rate.<br> keywords: {data mining;software 
engineering;FreeBSD;GNOME desktop;MSR research;datasets;mining challenge
 2010;mining software repositories;software ecosystem;Accuracy;Computer 
bugs;Computer science;Data mining;Ecosystems;Feedback;Open source 
software;Predictive models;Size control;Software tools},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463350&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463350&amp;isnumber=5463276</a><br><br>J. Davies, Hanyu Zhang, L. Nussbaum and D. M. German, "Perspectives on bugs in the Debian bug tracking system," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 86-89.<br>doi: 10.1109/MSR.2010.5463288<br>Abstract:
 Bugs in Debian differ from regular software bugs. They are usually 
associated with packages, instead of software modules. They are caused 
and fixed by source package uploads instead of code commits. The 
majority are reported by individuals who appear in the bug database 
once, and only once. There also exists a small group of bug reporters 
with over 1,000 bug reports each to their name. We also explore our idea
 that a high bug-frequency for an individual package might be an 
indicator of popularity instead of poor quality.<br> keywords: {program 
debugging;software quality;Debian bug tracking system;bug 
database;bug-frequency;software bug;software quality;source package 
upload;Cascading style sheets;Computer bugs;Data 
engineering;Informatics;Open source software;Prediction 
algorithms;Software engineering;Software measurement;Software 
quality;Software testing},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463288&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463288&amp;isnumber=5463276</a><br><br>A. Mauczka, C. Schanes, F. Fankhauser, M. Bernhart and T. Grechenig, "Mining security changes in FreeBSD," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 90-93.<br>doi: 10.1109/MSR.2010.5463289<br>Abstract:
 Current research on historical project data is rarely touching on the 
subject of security related information. Learning how security is 
treated in projects and which parts of a software are historically 
security relevant or prone to security changes can enhance the security 
strategy of a software project. We present a mining methodology for 
security related changes by modifying an existing method of software 
repository analysis. We use the gathered security changes to find out 
more about the nature of security in the FreeBSD project and we try to 
establish a link between the identified security changes and a tracker 
for security issues (security advisories). We give insights how security
 is presented in the FreeBSD project and show how the mined data and 
known security problems are connected.<br> keywords: {data 
mining;security of data;FreeBSD project;mining security changes;security
 advisories;software repository analysis;Computer industry;Data 
analysis;Data security;History;Information security;Mining 
industry;Performance analysis;Predictive models;Programming;Software 
performance},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463289&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463289&amp;isnumber=5463276</a><br><br>B. Luijten, J. Visser and A. Zaidman, "Assessment of issue handling efficiency," <em>Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on</em>, Cape Town, 2010, pp. 94-97.<br>doi: 10.1109/MSR.2010.5463292<br>Abstract:
 We mined the issue database of GNOME to assess how issues are handled. 
How many issues are submitted and resolved? Does the backlog grow or 
decrease? How fast are issues resolved? Does issue resolution speed 
increase or decrease over time? In which subproject are issues handled 
most efficiently? To answer such questions, we apply several 
visualization and quantification instruments to the raw issue data. In 
particular, we aggregate issues into four risk categories, based on 
their resolution time. These categories are the basis both for 
visualizing and ranking, which are used in concert for issue database 
exploration.<br> keywords: {data mining;database management 
systems;GNOME database;issue database exploration;issue database 
mining;issue handling;quantification instruments;risk 
categories;visualization instruments;Aggregates;Data 
visualization;Instruments;Visual databases;Defect resolution;Issue 
mining},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463292&amp;isnumber=5463276">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5463292&amp;isnumber=5463276</a><br><br>
</body></html>