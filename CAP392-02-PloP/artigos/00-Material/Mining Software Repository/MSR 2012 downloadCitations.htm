<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"></head><body>"[Front matter]," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. i-ii.<br>doi: 10.1109/MSR.2012.6224289<br>Abstract:
 The following topics are dealt with: software repositories; bug fixing 
and prediction; MSR trends; mining challenge; software analysis; and 
software quality.<br> keywords: {data mining;program debugging;software 
engineering;MSR trend;bug fixing;data mining;mining software 
repositories;software analysis;software quality},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224289&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224289&amp;isnumber=6224266</a><br><br>"Contents," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 1-3.<br>doi: 10.1109/MSR.2012.6224290<br>Abstract:
 The following topics are dealt with: software repositories; bug fixing 
and prediction; MSR trends; mining challenge; software analysis; and 
software quality.<br> keywords: {data mining;program debugging;software 
engineering;MSR trend;bug fixing;data mining;mining software 
repositories;software analysis;software quality},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224290&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224290&amp;isnumber=6224266</a><br><br>"Welcome from the chairs," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. iii-vii.<br>doi: 10.1109/MSR.2012.6224291<br>Abstract:
 The Ninth International Working Conference on Mining Software 
Repositories was held June 2-??????3 in Zurich, Switzerland, and 
co-??????located with the 2012 International Confer-?????? ence on 
Software Engineering (ICSE 2012). The first decade of MSR is coming 
quickly to and end: This is the fifth year that MSR has been a Working 
Conference, building on the strong foundation of four years as a 
successful ICSE work-??????shop. We are happy to report that the 
community of MSR researchers continues to grow, while at the same time 
the research being performed is maturing. This year saw a further 
increase in the total number of submissions: 64 full paper submissions 
(10 pages) and 22 short paper submissions (4 pages) for a total of 86. 
This total is 8 more than the 78 total submissions in 2011. Full paper 
submissions increased by 3 (64 vs. 61) while short paper submissions 
increased by 5 (22 vs. 17). Of the 64 full paper submissions, 18 were 
ultimately accepted, for a full paper acceptance rate of 28%. For short 
papers, of the 22 submissions 11 were accepted, for a short paper 
acceptance rate of 50%. Following last year's conference, MSR 2012 
accepted or rejected papers at their submitted length, and did not 
permit downgrading of a paper from full paper to short paper. Each paper
 received three reviews by members of the program committee. After we 
received all reviews, an online discussion process allowed variance 
among reviews to be understood, and in many cases, consensus to emerge. 
The program committee co-??????chairs then personally read all of the 
reviews and commentary prior to making final decisions. In the content 
of the papers, this year sees a continuation of previous topics, as well
 as the emergence of some new ones, such as the mining of mobile 
application repositories. Following MSR 2011, in MSR 2012, each full 
paper receives a 15-??????minute presentation slot and each short paper 
receives a 7-??????minute presentation slot. In keeping with MSR's 
roots- as a working conference, each session includes significant time 
for discussion. The conference has two keynote presentations this year.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224291&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224291&amp;isnumber=6224266</a><br><br>D. Zhang, "MSR 2012 keynote: Software analytics in practice — Approaches and experiences," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 1-1.<br>doi: 10.1109/MSR.2012.6224292<br>Abstract:
 Summary form only given. A list of the plenary sessions speakers and 
tracks is given. Following that are abstracts for all full papers 
published on the original conference proceedings CD.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224292&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224292&amp;isnumber=6224266</a><br><br>R. Lotufo, L. Passos and K. Czarnecki, "Towards improving bug tracking systems with game mechanisms," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 2-11.<br>doi: 10.1109/MSR.2012.6224293<br>Abstract:
 Low bug report quality and human conflicts pose challenges to keep bug 
tracking systems productive. This work proposes to address these issues 
by applying game mechanisms to bug tracking systems. We investigate the 
use of game mechanisms in Stack Overflow, an online community organized 
to resolve computer programming related problems, for which the 
improvements we seek for bug tracking systems also turn out to be 
relevant. The results of our Stack Overflow investigation show that its 
game mechanisms could be used to address these issues by motivating 
contributors to increase contribution frequency and quality, by 
filtering useful contributions, and by creating an agile and dependable 
moderation system. We proceed by mapping these mechanisms to open-source
 bug tracking systems, and find that most benefits are applicable. 
Additionally, our results motivate tailoring a reward and reputation 
system and summarizing bug reports as future directions for increasing 
the benefits of game mechanisms in bug tracking systems.<br> keywords: 
{program debugging;public domain software;software quality;bug report 
quality;computer programming related problem;game mechanism;human 
conflict;moderation system;online community;open-source bug tracking 
system;reward and reputation system;stack 
overflow;Collaboration;Communities;Ecosystems;Games;Open source 
software;Programming;Uncertainty},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224293&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224293&amp;isnumber=6224266</a><br><br>G. Gousios and D. Spinellis, "GHTorrent: Github's data from a firehose," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 12-21.<br>doi: 10.1109/MSR.2012.6224294<br>Abstract:
 A common requirement of many empirical software engineering studies is 
the acquisition and curation of data from software repositories. During 
the last few years, GitHub has emerged as a popular project hosting, 
mirroring and collaboration platform. GitHub provides an extensive REST 
API, which enables researchers to retrieve both the commits to the 
projects' repositories and events generated through user actions on 
project resources. GHTorrent aims to create a scalable off line mirror 
of GitHub's event streams and persistent data, and offer it to the 
research community as a service. In this paper, we present the project's
 design and initial implementation and demonstrate how the provided 
datasets can be queried and processed.<br> keywords: {application 
program interfaces;data acquisition;public domain software;software 
engineering;storage management;GHTorrent;Github data;REST 
API;collaboration platform;data acquisition;data curation;mirroring 
platform;open source software;project hosting platform;project 
resources;software engineering studies;software repositories;user 
actions;Communities;Distributed databases;Electronic 
mail;Organizations;Peer to peer 
computing;Protocols;GitHub;commits;dataset;events;repository},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224294&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224294&amp;isnumber=6224266</a><br><br>D. Posnett, P. Devanbu and V. Filkov, "MIC check: A correlation tactic for ESE data," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 22-31.<br>doi: 10.1109/MSR.2012.6224295<br>Abstract:
 Empirical software engineering researchers are concerned with 
understanding the relationships between outcomes of interest, e.g. 
defects, and process and product measures. The use of correlations to 
uncover strong relationships is a natural precursor to multivariate 
modeling. Unfortunately, correlation coefficients can be difficult 
and/or misleading to interpret. For example, a strong correlation occurs
 between variables that stand in a polynomial relationship; this may 
lead one mistakenly, and eventually misleadingly, to model a 
polynomially related variable in a linear regression. Likewise, a 
non-monotonic functional, or even non-functional relationship might be 
entirely missed by a correlation coefficient. Outliers can influence 
standard correlation measures, tied values can unduly influence even 
robust non-parametric rank correlation, measures, and smaller sample 
sizes can cause instability in correlation measures. A new bivariate 
measure of association, Maximal Information Coefficient (MIC) [1], 
promises to simultaneously discover if two variables have: a) any 
association, b) a functional relationship, and c) a nonlinear 
relationship. The MIC is a very useful complement to standard and rank 
correlation measures. It separately characterizes the existence of a 
relationship and its precise nature; thus, it enables more informed 
choices in modeling non-functional and nonlinear relationships, and a 
more nuanced indicator of potential problems with the values reported by
 standard and rank correlation measures. We illustrate the use of MIC 
using a variety of software engineering metrics. We study and explain 
the distributional properties of MIC and related measures in software 
engineering data, and illustrate the value of these measures for the 
empirical software engineering researcher.<br> keywords: {software 
metrics;ESE data;MIC check;bivariate measure;correlation 
coefficients;correlation measures;correlation tactic;even nonfunctional 
relationship;functional relationship;linear regression;maximal 
information coefficient;multivariate modeling;nonlinear 
relationship;nonmonotonic functional relationship;polynomial 
relationship;rank correlation measures;software engineering 
data;software engineering metrics;software engineering 
researcher;Atmospheric measurements;Correlation;Microwave integrated 
circuits;Size measurement;Software engineering;Software 
measurement;Standards},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224295&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224295&amp;isnumber=6224266</a><br><br>I. Keivanloo <em>et al</em>., "A Linked Data platform for mining software repositories," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 32-35.<br>doi: 10.1109/MSR.2012.6224296<br>Abstract:
 The mining of software repositories involves the extraction of both 
basic and value-added information from existing software repositories. 
The repositories will be mined to extract facts by different 
stakeholders (e.g. researchers, managers) and for various purposes. To 
avoid unnecessary pre-processing and analysis steps, sharing and 
integration of both basic and value-added facts are needed. In this 
research, we introduce SeCold, an open and collaborative platform for 
sharing software datasets. SeCold provides the first online software 
ecosystem Linked Data platform that supports data extraction and 
on-the-fly inter-dataset integration from major version control, issue 
tracking, and quality evaluation systems. In its first release, the 
dataset contains about two billion facts, such as source code 
statements, software licenses, and code clones from 18 000 software 
projects. In its second release the SeCold project will contain 
additional facts mined from issue trackers and versioning systems. Our 
approach is based on the same fundamental principle as Wikipedia: 
researchers and tool developers share analysis results obtained from 
their tools by publishing them as part of the SeCold portal and 
therefore make them an integrated part of the global knowledge domain. 
The SeCold project is an official member of the Linked Data dataset 
cloud and is currently the eighth largest online dataset available on 
the Web.<br> keywords: {data mining;software packages;code 
clones;collaborative platform;linked data platform;mining software 
repositories;on-the-fly inter-dataset integration;online software 
ecosystem linked data platform;software datasets;software 
licenses;software packages;software repositories;source code 
statements;value added information;Cloning;Communities;Data 
mining;Encyclopedias;Licenses;Ontologies;Software;Linked Data;fact 
sharing;software mining},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224296&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224296&amp;isnumber=6224266</a><br><br>C. Rodríguez-Bustos and J. Aponte, "How Distributed Version Control Systems impact open source software projects," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 36-39.<br>doi: 10.1109/MSR.2012.6224297<br>Abstract:
 Centralized Version Control Systems have been used by many open source 
projects for a long time. However, in recent years several widely-known 
projects have migrated their repositories to Distributed Version Control
 Systems, such as Mercurial, Bazaar, and Git. Such systems have 
technical features that allow contributors to work in new ways, as 
various different workflows are possible. We plan to study this 
migration process to assess how developers' organization and their 
contributions are affected. As a first step, we present an analysis of 
the Mozilla repositories, which migrated from CVS to Mercurial in 2007. 
This analysis reveals both expected and unexpected aspects of the 
contributors' activities.<br> keywords: {configuration 
management;distributed processing;project management;public domain 
software;Bazaar;CVS;Git;Mercurial;Mozilla repositories;centralized 
version control system;distributed version control system;migration 
process;open source software project;Communities;Control systems;Data 
mining;History;Merging;Open source software;Contribution 
measuring;Distributed Version Control System;Mining Software 
Repositories;Mozilla;Open Source Software},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224297&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224297&amp;isnumber=6224266</a><br><br>J. Park, M. Kim, B. Ray and D. H. Bae, "An empirical study of supplementary bug fixes," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 40-49.<br>doi: 10.1109/MSR.2012.6224298<br>Abstract:
 A recent study finds that errors of omission are harder for programmers
 to detect than errors of commission. While several change 
recommendation systems already exist to prevent or reduce omission 
errors during software development, there have been very few studies on 
why errors of omission occur in practice and how such errors could be 
prevented. In order to understand the characteristics of omission 
errors, this paper investigates a group of bugs that were fixed more 
than once in open source projects - those bugs whose initial patches 
were later considered incomplete and to which programmers applied 
supplementary patches. Our study on Eclipse JDT core, Eclipse SWT, and 
Mozilla shows that a significant portion of resolved bugs (22% to 33%) 
involves more than one fix attempt. Our manual inspection shows that the
 causes of omission errors are diverse, including missed porting 
changes, incorrect handling of conditional statements, or incomplete 
refactorings, etc. While many consider that missed updates to code 
clones often lead to omission errors, only a very small portion of 
supplementary patches (12% in JDT, 25% in SWT, and 9% in Mozilla) have a
 content similar to their initial patches. This implies that 
supplementary change locations cannot be predicted by code clone 
analysis alone. Furthermore, 14% to 15% of files in supplementary 
patches are beyond the scope of immediate neighbors of their initial 
patch locations - they did not overlap with the initial patch locations 
nor had direct structural dependencies on them (e.g. calls, accesses, 
subtyping relations, etc.). These results call for new types of omission
 error prevention approaches that complement existing change 
recommendation systems.<br> keywords: {inspection;program 
debugging;project management;public domain software;recommender 
systems;software maintenance;Eclipse JDT core;Eclipse SWT;Mozilla;change
 recommendation system;code clone analysis;conditional statement 
handling;manual inspection;omission error detection;omission error 
prevention approach;open source project;software 
development;supplementary bug fixes;supplementary patch;Cloning;Computer
 bugs;Databases;Dispersion;Entropy;History;Manuals;bug fixes;empirical 
study;patches;software evolution},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224298&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224298&amp;isnumber=6224266</a><br><br>B. Sisman and A. C. Kak, "Incorporating version histories in Information Retrieval based bug localization," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 50-59.<br>doi: 10.1109/MSR.2012.6224299<br>Abstract:
 Fast and accurate localization of software defects continues to be a 
difficult problem since defects can emanate from a large variety of 
sources and can often be intricate in nature. In this paper, we show how
 version histories of a software project can be used to estimate a prior
 probability distribution for defect proneness associated with the files
 in a given version of the project. Subsequently, these priors are used 
in an IR (Information Retrieval) framework to determine the posterior 
probability of a file being the cause of a bug. We first present two 
models to estimate the priors, one from the defect histories and the 
other from the modification histories, with both types of histories as 
stored in the versioning tools. Referring to these as the base models, 
we then extend them by incorporating a temporal decay into the 
estimation of the priors. We show that by just including the base 
models, the mean average precision (MAP) for bug localization improves 
by as much as 30%. And when we also factor in the time decay in the 
estimates of the priors, the improvements in MAP can be as large as 80%.<br>
 keywords: {information retrieval;probability;program debugging;software
 development management;bug localization;information retrieval;mean 
average precision;probability distribution;software defects;software 
project;temporal decay;version histories;Computational modeling;Computer
 bugs;Frequency estimation;History;Maximum likelihood 
estimation;Software;Bug Localization;Document Priors;Information 
Retrieval;Software Maintenance},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224299&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224299&amp;isnumber=6224266</a><br><br>N. Bettenburg, M. Nagappan and A. E. Hassan, "Think locally, act globally: Improving defect and effort prediction models," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 60-69.<br>doi: 10.1109/MSR.2012.6224300<br>Abstract:
 Much research energy in software engineering is focused on the creation
 of effort and defect prediction models. Such models are important means
 for practitioners to judge their current project situation, optimize 
the allocation of their resources, and make informed future decisions. 
However, software engineering data contains a large amount of 
variability. Recent research demonstrates that such variability leads to
 poor fits of machine learning models to the underlying data, and 
suggests splitting datasets into more fine-grained subsets with similar 
properties. In this paper, we present a comparison of three different 
approaches for creating statistical regression models to model and 
predict software defects and development effort. Global models are 
trained on the whole dataset. In contrast, local models are trained on 
subsets of the dataset. Last, we build a global model that takes into 
account local characteristics of the data. We evaluate the performance 
of these three approaches in a case study on two defect and two effort 
datasets. We find that for both types of data, local models show a 
significantly increased fit to the data compared to global models. The 
substantial improvements in both relative and absolute prediction errors
 demonstrate that this increased goodness of fit is valuable in 
practice. Finally, our experiments suggest that trends obtained from 
global models are too general for practical recommendations. At the same
 time, local models provide a multitude of trends which are only valid 
for specific subsets of the data. Instead, we advocate the use of trends
 obtained from global models that take into account local 
characteristics, as they combine the best of both worlds.<br> keywords: 
{data handling;learning (artificial intelligence);regression 
analysis;software engineering;effort prediction models;fine-grained 
subsets;machine learning models;prediction model defect;software 
engineering;splitting datasets;statistical regression models;Adaptation 
models;Biological system modeling;Data models;Measurement;Predictive 
models;Software;Software engineering;models;software 
metrics;techniques},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224300&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224300&amp;isnumber=6224266</a><br><br>R. Souza and C. Chavez, "Characterizing verification of bug fixes in two open source IDEs," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 70-73.<br>doi: 10.1109/MSR.2012.6224301<br>Abstract:
 Data from bug repositories have been used to enable inquiries about 
software product and process quality. Unfortunately, such repositories 
often contain inaccurate, inconsistent, or missing data, which can 
originate misleading results. In this paper, we investigate how well 
data from bug repositories support the discovery of details about the 
software verification process in two open source projects, Eclipse and 
NetBeans. We have been able do identify quality assurance teams in 
NetBeans and to detect a well-defined verification phase in Eclipse. A 
major challenge, however, was to identify the verification techniques 
used in the projects. Moreover, we found cases in which a large batch of
 bug fixes is simultaneously reported to be verified, although no 
software verification was actually done. Such mass verifications, if not
 acknowledged, threatens analyses that rely on information about 
software verification reported on bug repositories. Therefore, we 
recommend that the exploratory analyses presented in this paper precede 
inferences based on reported verifications.<br> keywords: {program 
debugging;program verification;public domain software;quality 
assurance;Eclipse;NetBeans;bug fixes;bug repositories;exploratory 
analyses;mass verifications;open source IDE;process quality;quality 
assurance teams;software product;software verification process;Computer 
bugs;Data mining;Inspection;Quality assurance;Software;Software 
engineering;Testing;bug tracking systems;empirical study;mining software
 repositories;software verification},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224301&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224301&amp;isnumber=6224266</a><br><br>Lucia, F. Thung, D. Lo and L. Jiang, "Are faults localizable?," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 74-77.<br>doi: 10.1109/MSR.2012.6224302<br>Abstract:
 Many fault localization techniques have been proposed to facilitate 
debugging activities. Most of them attempt to pinpoint the location of 
faults (i.e., localize faults) based on a set of failing and correct 
executions and expect debuggers to investigate a certain number of 
located program elements to find faults. These techniques thus assume 
that faults are localizable, i.e., only one or a few lines of code that 
are close to one another are responsible for each fault. However, in 
reality, are faults localizable? In this work, we investigate hundreds 
of real faults in several software systems, and find that many faults 
may not be localizable to a few lines of code and these include faults 
with high severity level.<br> keywords: {program debugging;software 
fault tolerance;bug severity;debugging activities;fault localization 
technique;software system;Computer bugs;Debugging;Educational 
institutions;Java;Manuals;Software systems;Bug Severity;Fault 
Locality;Fault Localization},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224302&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224302&amp;isnumber=6224266</a><br><br>A. Hindle, "Green mining: A methodology of relating software change to power consumption," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 78-87.<br>doi: 10.1109/MSR.2012.6224303<br>Abstract:
 Power consumption is becoming more and more important with the 
increased popularity of smart-phones, tablets and laptops. The threat of
 reducing a customer's battery-life now hangs over the software 
developer who asks, “will this next change be the one that causes my 
software to drain a customer's battery?” One solution is to detect power
 consumption regressions by measuring the power usage of tests, but this
 is time-consuming and often noisy. An alternative is to rely on 
software metrics that allow us to estimate the impact that a change 
might have on power consumption thus relieving the developer from 
expensive testing. This paper presents a general methodology for 
investigating the impact of software change on power consumption, we 
relate power consumption to software changes, and then investigate the 
impact of static OO software metrics on power consumption. We 
demonstrated that software change can effect power consumption using the
 Firefox web-browser and the Azureus/Vuze BitTorrent client. We found 
evidence of a potential relationship between some software metrics and 
power consumption. In conclusion, we explored the effect of software 
change on power consumption on two projects; and we provide an initial 
investigation on the impact of software metrics on power consumption.<br>
 keywords: {mobile computing;power aware computing;power 
consumption;software metrics;Azureus/Vuze BitTorrent client;Firefox 
web-browser;green mining;power consumption regressions;software 
change;software metrics;Data mining;Fires;Mobile communication;Power 
demand;Power measurement;Software;Software metrics;dynamic 
analysis;mining software repositories;power;power consumption;software 
metrics;sustainable-software},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224303&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224303&amp;isnumber=6224266</a><br><br>P. Rotella and S. Chulani, "Analysis of customer satisfaction survey data," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 88-97.<br>doi: 10.1109/MSR.2012.6224304<br>Abstract:
 Cisco Systems, Inc., conducts a customer satisfaction survey (CSAT) 
each year to gauge customer sentiment regarding Cisco products, 
technical support, partner- and Cisco-provided technical services, order
 fulfillment, and a number of other aspects of the companys business. 
The results of the analysis of this data are used for several purposes, 
including ascertaining the viability of new products, determining if 
customer support objectives are being met, setting engineering 
in-process and customer experience yearly metrics goals, and assessing, 
indirectly, the success of engineering initiatives. Analyzing this data,
 which includes 110,000 yearly sets of survey responses that address 
over 100 product and services categories, is in many respects 
complicated. For example, skip logic is an integral part of the survey 
mechanics, and forming aggregate views of customer sentiment is 
statistically challenging in this data environment. In this paper, we 
describe several of the various analysis approaches currently used, 
pointing out some situations where a high level of precision is not 
easily achieved, and some situations in which it is possible to easily 
end up with erroneous results. The analysis and statistical territory 
covered in this paper is in parts well-known and straightforward, but 
other parts, which we address, are susceptible to large inaccuracies and
 errors. We address several of these difficulties and develop reasonable
 solutions for two known issues, high missing value levels and high 
colinearity of independent variables.<br> keywords: {consumer 
behaviour;customer satisfaction;data analysis;statistical 
analysis;surveying;technical support services;CSAT survey;Cisco Systems 
Inc;Cisco products;Cisco-provided technical services;company 
business;customer experience yearly metrics goals;customer satisfaction 
survey data analysis;customer sentiment;customer support 
objectives;engineering initiatives;skip logic;statistical 
territory;survey mechanics;technical support;Analytical 
models;Couplings;Customer satisfaction;Mathematical 
model;Measurement;Software;CSAT survey (customer satisfaction 
survey);colinearity;customer satisfaction;data imputation;dominance 
analysis;listwise deletion;mean substitution;missing values},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224304&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224304&amp;isnumber=6224266</a><br><br>O. Baysal, R. Holmes and M. W. Godfrey, "Mining usage data and development artifacts," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 98-107.<br>doi: 10.1109/MSR.2012.6224305<br>Abstract:
 Software repository mining techniques generally focus on analyzing, 
unifying, and querying different kinds of development artifacts, such as
 source code, version control meta-data, defect tracking data, and 
electronic communication. In this work, we demonstrate how adding 
real-world usage data enables addressing broader questions of how 
software systems are actually used in practice, and by inference how 
development characteristics ultimately affect deployment, adoption, and 
usage. In particular, we explore how usage data that has been extracted 
from web server logs can be unified with product release history to 
study questions that concern both users' detailed dynamic behaviour as 
well as broad adoption trends across different deployment environments. 
To validate our approach, we performed a study of two open source web 
browsers: Firefox and Chrome. We found that while Chrome is being 
adopted at a consistent rate across platforms, Linux users have an order
 of magnitude higher rate of Firefox adoption. Also, Firefox adoption 
has been concentrated mainly in North America, while Chrome users appear
 to be more evenly distributed across the globe. Finally, we detected no
 evidence in age-specific differences in navigation behaviour among 
Chrome and Firefox users; however, we hypothesize that younger users are
 more likely to have more up-to-date versions than more mature users.<br>
 keywords: {data mining;meta data;online front-ends;public domain 
software;software development management;Chrome;Firefox;Linux 
users;North America;Web server logs;defect tracking data;development 
artifacts;electronic communication;open source Web browsers;product 
release history;software repository mining techniques;software 
systems;source code;usage data mining;version control 
meta-data;Browsers;Data mining;Fires;History;Linux;Operating systems;Web
 servers;dynamic behaviour;release history;usage mining;user adoption},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224305&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224305&amp;isnumber=6224266</a><br><br>M. Harman, Y. Jia and Y. Zhang, "App store mining and analysis: MSR for app stores," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 108-111.<br>doi: 10.1109/MSR.2012.6224306<br>Abstract:
 This paper introduces app store mining and analysis as a form of 
software repository mining. Unlike other software repositories 
traditionally used in MSR work, app stores usually do not provide source
 code. However, they do provide a wealth of other information in the 
form of pricing and customer reviews. Therefore, we use data mining to 
extract feature information, which we then combine with more readily 
available information to analyse apps' technical, customer and business 
aspects. We applied our approach to the 32,108 non-zero priced apps 
available in the Blackberry app store in September 2011. Our results 
show that there is a strong correlation between customer rating and the 
rank of app downloads, though perhaps surprisingly, there is no 
correlation between price and downloads, nor between price and rating. 
More importantly, we show that these correlation findings carry over to 
(and are even occasionally enhanced within) the space of data mined app 
features, providing evidence that our `App store MSR' approach can be 
valuable to app developers.<br> keywords: {data mining;pricing;software 
development management;software packages;Blackberry app store;app 
download;app store MSR;app store analysis;app store mining;business 
aspect;customer aspect;customer rating;customer review;data 
mining;feature information extraction;pricing;software repository 
mining;technical aspect;Business;Clustering algorithms;Correlation;Data 
mining;Feature extraction;Measurement;Software},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224306&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224306&amp;isnumber=6224266</a><br><br>E. Shihab, Y. Kamei and P. Bhattacharya, "Mining challenge 2012: The Android platform," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 112-115.<br>doi: 10.1109/MSR.2012.6224307<br>Abstract:
 The MSR Challenge offers researchers and practitioners in the area of 
Mining Software Repositories a common data set and asks them to put 
their mining tools and approaches on a dare. This year, the challenge is
 on the Android platform. We provided the change and bug report data for
 the Android platform asked researchers to uncover interesting findings 
related to the Android platform. In this paper, we describe the role of 
the MSR Challenge, highlight the data provided and summarize the papers 
accepted for inclusion in this year's challenge.<br> keywords: {data 
mining;operating systems (computers);program debugging;software 
engineering;storage management;Android platform;MSR Challenge;bug report
 data;data set;mining challenge 2012;mining software 
repositories;software repositories;Androids;Computer bugs;Data 
mining;Humanoid robots;Kernel;XML;Android Platform;MSR Challenge;Mining 
Software Repositories},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224307&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224307&amp;isnumber=6224266</a><br><br>M. Asaduzzaman, M. C. Bullock, C. K. Roy and K. A. Schneider, "Bug introducing changes: A case study with Android," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 116-119.<br>doi: 10.1109/MSR.2012.6224267<br>Abstract:
 Changes, a rather inevitable part of software development can cause 
maintenance implications if they introduce bugs into the system. By 
isolating and characterizing these bug introducing changes it is 
possible to uncover potential risky source code entities or issues that 
produce bugs. In this paper, we mine the bug introducing changes in the 
Android platform by mapping bug reports to the changes that introduced 
the bugs. We then use the change information to look for both potential 
problematic parts and dynamics in development that can cause maintenance
 implications. We believe that the results of our study can help better 
manage Android software development.<br> keywords: {mobile 
computing;program debugging;software maintenance;Android case 
study;Android platform;Android software development;bug report 
mapping;maintenance implications;source code;Androids;Computer 
bugs;Humanoid robots;Joining processes;Prediction 
algorithms;Programming;Software;Bug;bug report;change log;fixes},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224267&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224267&amp;isnumber=6224266</a><br><br>L. Martie, V. K. Palepu, H. Sajnani and C. Lopes, "Trendy bugs: Topic trends in the Android bug reports," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 120-123.<br>doi: 10.1109/MSR.2012.6224268<br>Abstract:
 Studying vast volumes of bug and issue discussions can give an 
understanding of what the community has been most concerned about, 
however the magnitude of documents can overload the analyst. We present 
an approach to analyze the development of the Android open source 
project by observing trends in the bug discussions in the Android open 
source project public issue tracker. This informs us of the features or 
parts of the project that are more problematic at any given point of 
time. In turn, this can be used to aid resource allocation (such as time
 and man power) to parts or features. We support these ideas by 
presenting the results of issue topic distributions over time using 
statistical analysis of the bug descriptions and comments for the 
Android open source project. Furthermore, we show relationships between 
those time distributions and major development releases of the Android 
OS.<br> keywords: {operating system kernels;program debugging;resource 
allocation;statistical analysis;Android OS;Android bug reports;Android 
open source project public issue tracker;documents magnitude;resource 
allocation;statistical analysis;topic distributions;trendy 
bugs;Androids;Google;Graphics;Humanoid robots;Java;Runtime;Smart 
phones;Android;bug logs;statistical trend analysis;topics},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224268&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224268&amp;isnumber=6224266</a><br><br>V.
 Guana, F. Rocha, A. Hindle and E. Stroulia, "Do the stars align? 
Multidimensional analysis of Android's layered architecture," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 124-127.<br>doi: 10.1109/MSR.2012.6224269<br>Abstract:
 In this paper we mine the Android bug tracker repository and study the 
characteristics of the architectural layers of the Android system. We 
have identified the locality of the Android bugs in the architectural 
layers of the its infrastructure, and analysed the bug lifetime patterns
 in each one of them. Additionally, we mined the bug tracker reporters 
and classified them according to its social centrality in the Android 
bug tracker community. We report three interesting findings, firstly 
while some architectural layers have a diverse interaction of people, 
attracting not only non-central reporters but highly important ones, 
other layers are mostly captivating for peripheral actors. Second, we 
exposed that even the bug lifetime is similar across the architectural 
layers, some of them have higher bug density and differential 
percentages of unsolved bugs. Finally, comparing the popularity 
distribution between layers, we have identified one particular layer 
that is more important to developers and users alike.<br> keywords: 
{data mining;mobile computing;operating systems (computers);program 
debugging;software architecture;Android bug tracker repository;Android 
layered architecture;Android operating system;Android 
system;architectural layers;bug lifetime pattern analysis;mobile 
devices;multidimensional analysis;popularity distribution;software 
services;Androids;Communities;Computer bugs;Humanoid 
robots;Kernel;Libraries;Runtime;architectural layer;bug 
tracker;lifetime;social centrality},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224269&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224269&amp;isnumber=6224266</a><br><br>W. Hu, D. Han, A. Hindle and K. Wong, "The build dependency perspective of Android's concrete architecture," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 128-131.<br>doi: 10.1109/MSR.2012.6224270<br>Abstract:
 Android is an operating system designed specifically for mobile 
devices. It has a layered architecture. In this paper, we extract 
Android's concrete layered architecture by analyzing the build 
dependency relation between Android sub-projects and use it to validate 
the proposed conceptual architecture. Our experiment shows that 
Android's concrete architecture conforms to the conceptual architecture.
 Apart from that, we also show the extracted architecture can help 
developers and users better understand the Android system and further 
demonstrate its potential benefits in studying the impact of changes.<br>
 keywords: {mobile computing;operating systems (computers);software 
architecture;Android concrete architecture;Android subprojects;Android 
system;conceptual architecture;extracted architecture;mobile 
devices;operating system;Androids;Computer 
architecture;Concrete;Humanoid 
robots;Kernel;Libraries;Runtime;Android;Architecture;Dependency},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224270&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224270&amp;isnumber=6224266</a><br><br>V. S. Sinha, S. Mani and M. Gupta, "MINCE: Mining change history of Android project," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 132-135.<br>doi: 10.1109/MSR.2012.6224271<br>Abstract:
 An analysis of commit history of Android reveals that Android has a 
code base of 550K files, where on an average each file has been modified
 8.7 times. 41% of files have been modified at-least once. In terms of 
contributors, it has an overall contributor community of 1563, with 
58.5% of them having made &gt;; 5 commits. Moreover, the contributor 
community shows high churn levels, with only 13 of contributors 
continuing from 2005 to 2011. In terms of industry participation, Google
 &amp; Android account for 22% of developers. Intel and RedHat account 
for 2% of contributors each and IBM, Oracle, TI, SGI account for another
 1% each. Android code can be classified into 5 sub-projects: kernel, 
platform, device, tools and toolchain. In this paper, we profile each of
 these sub-projects in terms of change volumes, contributor and industry
 participation. We further picked specific framework topics such as UI, 
security, whose understanding is required from perspective of developing
 apps over Android, and present some insights on community participation
 around the same.<br> keywords: {codes;data mining;operating systems 
(computers);Android code;Android project;Google &amp; Android 
account;IBM;Intel and RedHat account;MINCE;Oracle;SGI;TI;change 
volumes;churn levels;contributor community;device subprojects;industry 
participation;kernel subprojects;platform subproject;toolchain 
subprojects;tools 
subprojects;Androids;Communities;Companies;History;Humanoid 
robots;Kernel;Smart phones},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224271&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224271&amp;isnumber=6224266</a><br><br>L. A. Reina and G. Robles, "Mining for localization in Android," <em>Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on</em>, Zurich, 2012, pp. 136-139.<br>doi: 10.1109/MSR.2012.6224272<br>Abstract:
 Localization, and in particular translation, is a key aspect of modern 
end-user software applications. Open source systems have traditionally 
taken advantage of distributed and volunteer collaboration to carry 
localization tasks. In this paper, we will analyze the Android source 
code repository to know how localization and translation is managed: who
 participates in this kind of tasks, if the translation workflows, 
participants and processes follow the same patterns as the rest of the 
development, and if the Android project takes benefit from external 
contributions. Our results show that Android should ease the 
localization tasks to benefit from external contributions. Steps towards
 obtaining a specialized team as found in many other free software 
projects are also encouraged.<br> keywords: {data mining;operating 
systems (computers);public domain software;software engineering;Android 
source code repository;open source system;software localization;software
 repository mining;software translation;Androids;Data mining;Humanoid 
robots;Kernel;Linux;Software 
engineering;Android;i18n;l10n;localization;mining software 
repositories;translation},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224272&amp;isnumber=6224266">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6224272&amp;isnumber=6224266</a><br><br>
</body></html>