<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"></head><body>"[Front cover]," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, USA, 2013, pp. 1-1.<br>doi: 10.1109/MSR.2013.6623992<br>Abstract: Presents the front cover or splash screen of the proceedings record.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623992&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623992&amp;isnumber=6623991</a><br><br>"[Front matter]," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, USA, 2013, pp. 1-2.<br>doi: 10.1109/MSR.2013.6623993<br>Abstract:
 Conference proceedings front matter may contain various advertisements,
 welcome messages, committee or program information, and other 
miscellaneous conference information. This may in some cases also 
include the cover art, table of contents, copyright statements, 
title-page or half title-pages, blank pages, venue maps or other general
 information relating to the conference that was part of the original 
conference proceedings.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623993&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623993&amp;isnumber=6623991</a><br><br>"Contents," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 1-4.<br>doi: 10.1109/MSR.2013.6623994<br>Abstract:
 The following topics are dealt with: mining software repositories; bug 
triaging; mobile MSR; software evolution; analysis of bug reports; 
software ecosystems; big data; bug classification; bug localization; 
change classification; change localization; social mining; search-driven
 development; mining unstructured data; and predictor models.<br> 
keywords: {data mining;software engineering;big data;bug 
classification;bug localization;bug report analysis;bug triaging;change 
classification;change localization;mining software repositories;mobile 
MSR;predictor models;search-driven development;social mining;software 
ecosystems;software evolution;unstructured data mining},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623994&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623994&amp;isnumber=6623991</a><br><br>"Welcome from the Chairs," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. iii-viii.<br>doi: 10.1109/MSR.2013.6623995<br>Abstract: Presents the introductory welcome message from the conference proceedings.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623995&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623995&amp;isnumber=6623991</a><br><br>G. C. Murphy, "What is software development productivity, anyway? (Keynote)," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, USA, 2013, pp. 1-1.<br>doi: 10.1109/MSR.2013.6623996<br>Abstract:
 Businesses and consumers all want more software faster. The seemingly 
ever-increasing demand for more software suggests the need to not only 
increase production capabilities but also to produce more with the 
resources available for production. In other words, software development
 productivity needs to increase. But what is software development 
productivity anyway? In this talk, I will explore various ways in which 
productivity, both in general and for software development, has been 
characterized and will explore ways in which mining software repository 
information can help accelerate both software development productivity 
and innovation.<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623996&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623996&amp;isnumber=6623991</a><br><br>R.
 Shokripour, J. Anvik, Z. M. Kasirun and S. Zamani, "Why so complicated?
 Simple term filtering and weighting for location-based bug report 
assignment recommendation," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 2-11.<br>doi: 10.1109/MSR.2013.6623997<br>Abstract:
 Large software development projects receive many bug reports and each 
of these reports needs to be triaged. An important step in the triage 
process is the assignment of the report to a developer. Most previous 
efforts towards improving bug report assignment have focused on using an
 activity-based approach. We address some of the limitations of 
activity-based approaches by proposing a two-phased location-based 
approach where bug report assignment recommendations are based on the 
predicted location of the bug. The proposed approach utilizes a noun 
extraction process on several information sources to determine bug 
location information and a simple term weighting scheme to provide a bug
 report assignment recommendation. We found that by using a 
location-based approach, we achieved an accuracy of 89.41% and 59.76% 
when recommending five developers for the Eclipse and Mozilla projects, 
respectively.<br> keywords: {information filtering;program 
debugging;project management;software management;Eclipse project;Mozilla
 project;activity-based approach;bug location information;bug report 
assignment recommendations;information sources;location-based bug report
 assignment recommendation;noun extraction process;term filtering;term 
weighting scheme;two-phased location-based approach;Accuracy;Computer 
bugs;Data mining;Indexes;Logic gates;Noise;Software;Bug Report 
Assignment;File Activity Histories;Mining Software Artifacts;Named 
Entity Recognition;POS Filtering},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623997&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623997&amp;isnumber=6623991</a><br><br>D. Mukherjee and M. Garg, "Which work-item updates need your response?," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 12-21.<br>doi: 10.1109/MSR.2013.6623998<br>Abstract:
 Work-item notifications alert the team collaborating on a work-item 
about any update to the work-item (e.g., addition of comments, change in
 status). However, as software professionals get involved with multiple 
tasks in project(s), they are inundated by too many notifications from 
the work-item tool. Users are upset that they often miss the 
notifications that solicit their response in the crowd of mostly useless
 ones. We investigate the severity of this problem by studying the 
work-item repositories of two large collaborative projects and 
conducting a user study with one of the project teams. We find that, on 
an average, only 1 out of every 5 notifications that are received by the
 users require a response from them. We propose TWINY - a machine 
learning based approach to predict whether a notification will prompt 
any action from its recipient. Such a prediction can help to suitably 
mark up notifications and to decide whether a notification needs to be 
sent out immediately or be bundled in a message digest. We conduct 
empirical studies to evaluate the efficacy of different classification 
techniques in this setting. We find that incremental learning algorithms
 are ideally suited, and ensemble methods appear to give the best 
results in terms of prediction accuracy.<br> keywords: {learning 
(artificial intelligence);pattern classification;project 
management;software development management;TWINY;classification 
techniques;collaborative projects;ensemble methods;incremental learning 
algorithms;machine learning;project teams;work-item 
repositories;work-item update;Adaptation models;Collaboration;Electronic
 mail;History;Labeling;Software;Training},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623998&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623998&amp;isnumber=6623991</a><br><br>H. Naguib, N. Narayan, B. Brügge and D. Helal, "Bug report assignee recommendation using activity profiles," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 22-30.<br>doi: 10.1109/MSR.2013.6623999<br>Abstract:
 One question which frequently arises within the context of artifacts 
stored in a bug tracking repository is: “who should work on this bug 
report?” A number of approaches exist to semi-automatically identify and
 recommend developers, e.g. using machine learning techniques and social
 networking analysis. In this work, we propose a new approach for 
assignee recommendation leveraging user activities in a bug tracking 
repository. Within the bug tracking repository, an activity profile is 
created for each user from the history of all his activities (i.e. 
review, assign, and resolve). This profile, to some extent, indicates 
the user's role, expertise, and involvement in this project. These 
activities influence and contribute to the identification and ranking of
 suitable assignees. In order to evaluate our work, we apply it to bug 
reports of three different projects. Our results indicate that the 
proposed approach is able to achieve an average hit ratio of 88%. 
Comparing this result to the LDA-SVM - based assignee recommendation 
technique, it was found that the proposed approach performs better.<br> 
keywords: {program debugging;recommender systems;software 
engineering;average hit ratio;bug report assignee recommendation;bug 
report assignment;bug report resolving;bug report review;bug tracking 
repository;user activity profiles;user expertise;user involvement;user 
role;Data mining;Databases;Equations;History;Mathematical model;Open 
source software;Activity profile;assignee recommendation;bug report;bug 
tracking},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623999&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6623999&amp;isnumber=6623991</a><br><br>R. Stevens, J. Ganz, V. Filkov, P. Devanbu and H. Chen, "Asking for (and about) permissions used by Android apps," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 31-40.<br>doi: 10.1109/MSR.2013.6624000<br>Abstract:
 Security policies, which specify what applications are allowed to do, 
are notoriously difficult to specify correctly. Many applications were 
found to request over-liberal permissions. On mobile platforms, this 
might prevent a cautious user from installing an otherwise harmless 
application or, even worse, increase the attack surface in vulnerable 
applications. As a result of such difficulties, programmers frequently 
ask about them in on-line fora. Our goal is to gain some insight into 
both the misuse of permissions and the discussions of permissions in 
on-line fora. We analyze about 10,000 free apps from popular Android 
markets and found a significant sub-linear relationship between the 
popularity of a permission and the number of times when it is misused. 
We also study the relationship of permission use and the number of 
questions about the permission on StackOverflow. Finally, we study the 
effect of the influence of a permission (the functionality that it 
controls) and the interference of a permission (the number of other 
permissions that influence the same classes) on the occurrence of both 
permission misuse and permission discussions in StackOverflow.<br> 
keywords: {Linux;Web sites;authorisation;mobile computing;Android 
markets;StackOverflow;free-Android applications;mobile platforms;online 
fora;over-liberal permission request;permission discussions;permission 
interference;permission misuse;permission popularity;security 
policies;sublinear relationship;Androids;Documentation;Humanoid 
robots;Interference;Java;Security;Software},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624000&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624000&amp;isnumber=6623991</a><br><br>C. Iacob and R. Harrison, "Retrieving and analyzing mobile apps feature requests from online reviews," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 41-44.<br>doi: 10.1109/MSR.2013.6624001<br>Abstract:
 Mobile app reviews are valuable repositories of ideas coming directly 
from app users. Such ideas span various topics, and in this paper we 
show that 23.3% of them represent feature requests, i.e. comments 
through which users either suggest new features for an app or express 
preferences for the re-design of already existing features of an app. 
One of the challenges app developers face when trying to make use of 
such feedback is the massive amount of available reviews. This makes it 
difficult to identify specific topics and recurring trends across 
reviews. Through this work, we aim to support such processes by 
designing MARA (Mobile App Review Analyzer), a prototype for automatic 
retrieval of mobile app feature requests from online reviews. The design
 of the prototype is a) informed by an investigation of the ways users 
express feature requests through reviews, b) developed around a set of 
pre-defined linguistic rules, and c) evaluated on a large sample of 
online reviews. The results of the evaluation were further analyzed 
using Latent Dirichlet Allocation for identifying common topics across 
feature requests, and the results of this analysis are reported in this 
paper.<br> keywords: {Internet;computational linguistics;information 
retrieval;mobile computing;natural language processing;MARA 
design;latent Dirichlet allocation;linguistic rules;mobile app review 
analyzer;mobile app reviews;mobile apps feature request analysis;mobile 
apps feature request retrieval;online reviews;Context;Feature 
extraction;Measurement;Mobile 
communication;Pragmatics;Prototypes;Resource management;Online 
reviews;feature requests;mobile apps},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624001&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624001&amp;isnumber=6623991</a><br><br>M. Mukadam, C. Bird and P. C. Rigby, "Gerrit software code review data from Android," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 45-48.<br>doi: 10.1109/MSR.2013.6624002<br>Abstract:
 Over the past decade, a number of tools and systems have been developed
 to manage various aspects of the software development lifecycle. Until 
now, tool supported code review, an important aspect of software 
development, has been largely ignored. With the advent of open source 
code review tools such as Gerrit along with projects that use them, code
 review data is now available for collection, analysis, and 
triangulation with other software development data. In this paper, we 
extract Android peer review data from Gerrit. We describe the Android 
peer review process, the reverse engineering of the Gerrit JSON API, our
 data mining and cleaning methodology, database schema, and provide an 
example of how the data can be used to answer an empirical software 
engineering question. The database is available for use by the research 
community.<br> keywords: {application program interfaces;data 
mining;database management systems;operating system kernels;public 
domain software;reverse engineering;software development 
management;software tools;Android;Android peer review data 
extract;Android peer review process;Gerrit JSON API;Gerrit software code
 review data;data cleaning methodology;data mining methodology;database 
schema;open source code review tools;reverse engineering;software 
development data;software development lifecycle management;software 
engineering;Androids;Data mining;Databases;Humanoid 
robots;Servers;Software},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624002&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624002&amp;isnumber=6623991</a><br><br>K.
 Hamasaki, R. G. Kula, N. Yoshida, A. E. C. Cruz, K. Fujiwara and H. 
Iida, "Who does what during a code review? Datasets of OSS peer review 
repositories," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 49-52.<br>doi: 10.1109/MSR.2013.6624003<br>Abstract:
 We present four datasets that are focused on the general roles of OSS 
peer review members. With data mined from both an integrated peer review
 system and code source repositories, our rich datasets comprise of peer
 review data that was automatically recorded. Using the Android project 
as a case study, we describe our extraction methodology, the datasets 
and their application used for three separate studies. Our datasets are 
available online at http://sdlab.naist.jp/reviewmining/.<br> keywords: 
{data mining;public domain software;software quality;Android project;OSS
 peer review repositories;code review;code source repositories;data 
mining;extraction methodology;integrated peer review system;software 
quality assurance activity;Androids;Complexity theory;Data 
mining;Humanoid robots;Radiation detectors;Social network 
services;Software;Open Source Software;Peer Review Repository 
Mining;Quality Assurance},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624003&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624003&amp;isnumber=6623991</a><br><br>M. Allamanis and C. Sutton, "Why, when, and what: Analyzing Stack Overflow questions by topic, type, and code," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 53-56.<br>doi: 10.1109/MSR.2013.6624004<br>Abstract:
 Questions from Stack Overflow provide a unique opportunity to gain 
insight into what programming concepts are the most confusing. We 
present a topic modeling analysis that combines question concepts, 
types, and code. Using topic modeling, we are able to associate 
programming concepts and identifiers (like the String class) with 
particular types of questions, such as, “how to perform encoding”.<br> 
keywords: {Web sites;high level languages;statistical analysis;Stack 
Overflow question analysis;codes;encoding;identifiers;programming 
concepts;question concepts;question types;string class;topic modeling 
analysis;Androids;Cascading style sheets;Humanoid 
robots;Java;Programming;Software},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624004&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624004&amp;isnumber=6623991</a><br><br>J.
 C. Campbell, C. Zhang, Z. Xu, A. Hindle and J. Miller, "Deficient 
documentation detection a methodology to locate deficient project 
documentation using topic analysis," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 57-60.<br>doi: 10.1109/MSR.2013.6624005<br>Abstract:
 A project's documentation is the primary source of information for 
developers using that project. With hundreds of thousands of 
programming-related questions posted on programming Q&amp;A websites, 
such as Stack Overflow, we question whether the developer-written 
documentation provides enough guidance for programmers. In this study, 
we wanted to know if there are any topics which are inadequately covered
 by the project documentation. We combined questions from Stack Overflow
 and documentation from the PHP and Python projects. Then, we applied 
topic analysis to this data using latent Dirichlet allocation (LDA), and
 found topics in Stack Overflow that did not overlap the project 
documentation. We successfully located topics that had deficient project
 documentation. We also found topics in need of tutorial documentation 
that were outside of the scope of the PHP or Python projects, such as 
MySQL and HTML.<br> keywords: {project management;system 
documentation;LDA;PHP projects;Python projects;Stack Overflow;deficient 
project documentation detection;developer-written documentation;latent 
Dirichlet allocation;programming Q&amp;A websites;topic analysis;Data 
mining;Documentation;HTML;Internet;Programming;Resource 
management;Software;LDA;Stack Overflow;documentation;topic analysis},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624005&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624005&amp;isnumber=6623991</a><br><br>W. Wang and M. W. Godfrey, "Detecting API usage obstacles: A study of iOS and Android developer questions," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 61-64.<br>doi: 10.1109/MSR.2013.6624006<br>Abstract:
 Software frameworks provide sets of generic functionalities that can be
 later customized for a specific task. When developers invoke API 
methods in a framework, they often encounter obstacles in finding the 
correct usage of the API, let alone to employ best practices. Previous 
research addresses this line of questions by mining API usage patterns 
to induce API usage templates, by conducting and compiling interviews of
 developers, and by inferring correlations among APIs. In this paper, we
 analyze API-related posts regarding iOS and Android development from a 
Q&amp;A Web site, stackoverflow.com. Assuming that API-related posts are
 primarily about API usage obstacles, we find several iOS and Android 
API classes that appear to be particularly likely to challenge 
developers, even after we factor out API usage hotspots, inferred by 
modelling API usage of open source iOS and Android applications. For 
each API with usage obstacles, we further apply a topic mining tool to 
posts that are tagged with the API, and we discover several repetitive 
scenarios in which API usage obstacles occur. We consider our work as a 
stepping stone towards understanding API usage challenges based on 
forum-based input from a multitude of developers, input that is 
prohibitively expensive to collect through interviews. Our method helps 
to motivate future research in API usage, and can allow designers of 
platforms - such as iOS and Android - to better understand the problems 
developers have in using their platforms, and to make corresponding 
improvements.<br> keywords: {Linux;Web sites;application program 
interfaces;data mining;public domain software;software engineering;API 
method invoking;API usage hotspots;API usage obstacle 
detection;API-related post analysis;Android API classes;Android 
developer questions;Q&amp;A Web site;application programming 
interfaces;forum-based input;generic functionalities;open source 
iOS;software frameworks;stackoverflow.com;topic mining 
tool;Androids;Data mining;Documentation;Humanoid 
robots;Libraries;Software;Software engineering},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624006&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624006&amp;isnumber=6623991</a><br><br>S. Grant and B. Betts, "Encouraging user behaviour with achievements: An empirical study," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 65-68.<br>doi: 10.1109/MSR.2013.6624007<br>Abstract:
 Stack Overflow, a question and answer Web site, uses a reward system 
called badges to publicly reward users for their contributions to the 
community. Badges are used alongside a reputation score to reward 
positive behaviour by relating a user's site identity with their 
perceived expertise and respect in the community. A greater number of 
badges associated with a user profile in some way indicates a higher 
level of authority, leading to a natural incentive for users to attempt 
to achieve as many badges as possible. In this study, we examine the 
publicly available logs for Stack Overflow to examine three of these 
badges in detail. We look at the effect of one badge in context on an 
individual user level and at the global scope of three related badges 
across all users by mining user behaviour around the time that the badge
 is awarded. This analysis supports the claim that badges can be used to
 influence user behaviour by demonstrating one instance of an increase 
in user activity related to a badge immediately before it is awarded 
when compared to the period afterwards.<br> keywords: {Web 
sites;behavioural sciences computing;data mining;Stack 
Overflow;authority level;badges;empirical study;natural 
incentive;positive behaviour reward system;publicly available 
logs;question-and-answer Web site;reputation score;user 
achievements;user activity;user behaviour mining;user profile;user site 
identity;Awards activities;Bars;Communities;Data 
mining;Games;History;Silver},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624007&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624007&amp;isnumber=6623991</a><br><br>P. Morrison and E. Murphy-Hill, "Is programming knowledge related to age? An exploration of stack overflow," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 69-72.<br>doi: 10.1109/MSR.2013.6624008<br>Abstract:
 Becoming an expert at programming is thought to take an estimated 
10,000 hours of deliberate practice. But what happens after that? Do 
programming experts continue to develop, do they plateau, or is there a 
decline at some point? A diversity of opinion exists on this matter, but
 many seem to think that aging brings a decline in adoption and 
absorption of new programming knowledge. We develop several research 
questions on this theme, and draw on data from StackOverflow (SO) to 
address these questions. The goal of this research is to support career 
planning and staff development for programmers by identifying 
age-related trends in SO data. We observe that programmer reputation 
scores increase relative to age well into the 50's, that programmers in 
their 30's tend to focus on fewer areas relative to those younger or 
older in age, and that there is not a strong correlation between age and
 scores in specific knowledge areas.<br> keywords: {age issues;computer 
literacy;planning;professional aspects;social aspects of automation;SO 
data;Stack Overflow;age-related trends;career planning;programmer 
reputation scores;programming knowledge;staff development;Aging;Data 
mining;Programming 
profession;Sociology;Software;Statistics;Aging;Mining;Programming 
Knowledge;Software Repositories;Stack Overflow},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624008&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624008&amp;isnumber=6623991</a><br><br>A.
 K. Saha, R. K. Saha and K. A. Schneider, "A discriminative model 
approach for suggesting tags automatically for Stack Overflow 
questions," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 73-76.<br>doi: 10.1109/MSR.2013.6624009<br>Abstract:
 Annotating documents with keywords or `tags' is useful for categorizing
 documents and helping users find a document efficiently and quickly. 
Question and answer (Q&amp;A) sites also use tags to categorize 
questions to help ensure that their users are aware of questions related
 to their areas of expertise or interest. However, someone asking a 
question may not necessarily know the best way to categorize or tag the 
question, and automatically tagging or categorizing a question is a 
challenging task. Since a Q&amp;A site may host millions of questions 
with tags and other data, this information can be used as a training and
 test dataset for approaches that automatically suggest tags for new 
questions. In this paper, we mine data from millions of questions from 
the Q&amp;A site Stack Overflow, and using a discriminative model 
approach, we automatically suggest question tags to help a questioner 
choose appropriate tags for eliciting a response.<br> keywords: {Web 
sites;data mining;document handling;question answering (information 
retrieval);Q&amp;A site;Stack Overflow questions;automatic question 
categorization;automatic question tagging;automatic tag suggestion;data 
mining;discriminative model approach;document annotation;document 
categorization;document keywords;document tags;question-and-answer 
sites;test dataset;training dataset;Accuracy;Prediction 
algorithms;Predictive models;Support vector 
machines;Tagging;Training;Vectors;Machine learning;automatic 
tagging;discriminative model},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624009&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624009&amp;isnumber=6623991</a><br><br>V. S. Sinha, S. Mani and M. Gupta, "Exploring activeness of users in QA forums," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 77-80.<br>doi: 10.1109/MSR.2013.6624010<br>Abstract:
 Success of a Q&amp;A forum depends on volume of content (questions and 
answers) and quality of content (are the questions asked relevant, 
answers provided correct etc). Community participation is essential to 
create and curate content. Since their inception in 2008, stack exchange
 based forums have been able to engage a large number of users to create
 a rich repository of good quality questions and answers. In this paper,
 we wish to investigate the “activeness” of users in the stackexchange 
network particularly from a perspective of content creation. We also 
attempt to measure how the forums' incentive mechanism has enabled 
user's activeness. Further, we investigate how user's have diffused to 
other parts of the stack exchange network over time, hence bootstrapping
 new forums.<br> keywords: {Web sites;question answering (information 
retrieval);QA forums;content creation;content quality;content 
volume;stack exchange based forums;stack-exchange network;user 
activeness;Androids;Awards activities;Communities;Data mining;Electronic
 mail;Games;Humanoid robots},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624010&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624010&amp;isnumber=6623991</a><br><br>C. Gómez, B. Cleary and L. Singer, "A study of innovation diffusion through link sharing on stack overflow," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 81-84.<br>doi: 10.1109/MSR.2013.6624011<br>Abstract:
 It is poorly understood how developers discover and adopt software 
development innovations such as tools, libraries, frameworks, or web 
sites that support developers. Yet, being aware of and choosing 
appropriate tools and components can have a significant impact on the 
outcome of a software project. In our study, we investigate link sharing
 on Stack Overflow to gain insights into how software developers 
discover and disseminate innovations. We find that link sharing is a 
significant phenomenon on Stack Overflow, that Stack Overflow is an 
important resource for software development innovation dissemination and
 that its part of a larger interconnected network of online resources 
used and referenced by developers. This knowledge can guide researchers 
and practitioners who build tools and services that support software 
developers in the exploration, discovery, and adoption of software 
development innovations.<br> keywords: {innovation management;project 
management;software development management;Stack Overflow;innovation 
diffusion;link sharing;software development innovation 
discovery;software development innovation dissemination;software 
development innovation exploration;software 
project;Documentation;Ecosystems;Encoding;Encyclopedias;Libraries;Software;Technological
 innovation},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624011&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624011&amp;isnumber=6623991</a><br><br>S. Subramanian and R. Holmes, "Making sense of online code snippets," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 85-88.<br>doi: 10.1109/MSR.2013.6624012<br>Abstract:
 Stack Overflow contains a large number of high-quality source code 
snippets. The quality of these snippets has been verified by users 
marking them as solving a specific problem. Stack Overflow treats source
 code snippets as plain text and searches surface snippets as they would
 any other text. Unfortunately, plain text does not capture the 
structural qualities of these snippets; for example, snippets frequently
 refer to specific API (e.g., Android), but by treating the snippets as 
text, linkage to the Android API is not always apparent. We perform 
snippet analysis to extract structural information from short plain-text
 snippets that are often found in Stack Overflow. This analysis is able 
to identify 253,137 method calls and type references from 21,250 Stack 
Overflow code snippets. We show how identifying these structural 
relationships from snippets could perform better than lexical search 
over code blocks in practice.<br> keywords: {Linux;Web sites;application
 program interfaces;information retrieval;software quality;Android 
API;Stack Overflow code snippets;code blocks;high-quality source code 
snippets;method calls;online code snippets;plain text;snippet structural
 qualities;surface snippet search;type references;Androids;Data 
mining;Documentation;Educational institutions;Humanoid 
robots;Java;Libraries},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624012&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624012&amp;isnumber=6623991</a><br><br>A.
 Bosu, C. S. Corley, D. Heaton, D. Chatterji, J. C. Carver and N. A. 
Kraft, "Building reputation in StackOverflow: An empirical 
investigation," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 89-92.<br>doi: 10.1109/MSR.2013.6624013<br>Abstract:
 StackOverflow (SO) contributors are recognized by reputation scores. 
Earning a high reputation score requires technical expertise and 
sustained effort. We analyzed the SO data from four perspectives to 
understand the dynamics of reputation building on SO. The results of our
 analysis provide guidance to new SO contributors who want to earn high 
reputation scores quickly. In particular, the results indicate that the 
following activities can help to build reputation quickly: answering 
questions related to tags with lower expertise density, answering 
questions promptly, being the first one to answer a question, being 
active during off peak hours, and contributing to diverse areas.<br> 
keywords: {data analysis;data mining;software engineering;SO 
contributors;SO data analysis;expertise density;reputation 
scores;stackoverflow contributors;technical 
expertise;Buildings;Communities;Correlation;Gold;Java;Measurement;Silver;Mining
 repositories;StackOverflow;reputation},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624013&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624013&amp;isnumber=6623991</a><br><br>M. Linares-Vásquez, B. Dit and D. Poshyvanyk, "An exploratory analysis of mobile development issues using stack overflow," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 93-96.<br>doi: 10.1109/MSR.2013.6624014<br>Abstract:
 Question &amp; answer (Q&amp;A) websites, such as Stack Overflow (SO), 
are widely used by developers to find and provide answers to technical 
issues and concerns in software development. Mobile development is not 
an exception to the rule. In the latest SO dump, more than 400K 
questions were labeled with tags related to mobile technologies. 
Although, previous works have analyzed the main topics and trends in SO 
threads, there are no studies devoted specifically to mobile 
development. In this paper we used topic modeling techniques to extract 
hot-topics from mobile-development related questions. Our findings 
suggest that most of the questions include topics related to general 
questions and compatibility issues, and the most specific topics, such 
as crash reports and database connection, are present in a reduced set 
of questions.<br> keywords: {Web sites;mobile computing;question 
answering (information retrieval);software engineering;SO dump;Stack 
Overflow;compatibility issues;crash reports;database 
connection;exploratory analysis;mobile development 
issues;mobile-development related questions;question &amp; answer 
Websites;topic modeling techniques;Analytical models;Androids;Computer 
crashes;Entropy;Humanoid robots;Mobile communication;Software;Stack 
Overflow;mining software repositories;mobile platforms;topic modeling},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624014&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624014&amp;isnumber=6623991</a><br><br>M.
 Asaduzzaman, A. S. Mashiyat, C. K. Roy and K. A. Schneider, "Answering 
questions about unanswered questions of Stack Overflow," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 97-100.<br>doi: 10.1109/MSR.2013.6624015<br>Abstract:
 Community-based question answering services accumulate large volumes of
 knowledge through the voluntary services of people across the globe. 
Stack Overflow is an example of such a service that targets developers 
and software engineers. In general, questions in Stack Overflow are 
answered in a very short time. However, we found that the number of 
unanswered questions has increased significantly in the past two years. 
Understanding why questions remain unanswered can help information 
seekers improve the quality of their questions, increase their chances 
of getting answers, and better decide when to use Stack Overflow 
services. In this paper, we mine data on unanswered questions from Stack
 Overflow. We then conduct a qualitative study to categorize unanswered 
questions, which reveals characteristics that would be difficult to find
 otherwise. Finally, we conduct an experiment to determine whether we 
can predict how long a question will remain unanswered in Stack 
Overflow.<br> keywords: {data mining;question answering (information 
retrieval);software engineering;Stack Overflow services;community-based 
question answering services;data mining;information seekers;software 
developers;software engineers;unanswered questions;voluntary 
services;Communities;Data mining;Knowledge discovery;Predictive 
models;Software;Taxonomy;Time factors;Stack 
Overflow;prediction;question-answer},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624015&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624015&amp;isnumber=6623991</a><br><br>Y. Jiang, B. Adams and D. M. German, "Will my patch make it? And how fast? Case study on the Linux kernel," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 101-110.<br>doi: 10.1109/MSR.2013.6624016<br>Abstract:
 The Linux kernel follows an extremely distributed reviewing and 
integration process supported by 130 developer mailing lists and a 
hierarchy of dozens of Git repositories for version control. Since not 
every patch can make it and of those that do, some patches require a lot
 more reviewing and integration effort than others, developers, 
reviewers and integrators need support for estimating which patches are 
worthwhile to spend effort on and which ones do not stand a chance. This
 paper crosslinks and analyzes eight years of patch reviews from the 
kernel mailing lists and committed patches from the Git repository to 
understand which patches are accepted and how long it takes those 
patches to get to the end user. We found that 33% of the patches makes 
it into a Linux release, and that most of them need 3 to 6 months for 
this. Furthermore, that patches developed by more experienced developers
 are more easily accepted and faster reviewed and integrated. 
Additionally, reviewing time is impacted by submission time, the number 
of affected subsystems by the patch and the number of requested 
reviewers.<br> keywords: {Linux;configuration management;Linux 
kernel;Linux release;committed patches;developer mailing lists;extremely
 distributed reviewing process;git repositories;integration 
process;kernel mailing lists;patch reviews;requested 
reviewers;submission time;version control;Electronic 
mail;Guidelines;Joining processes;Kernel;Linux;Measurement},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624016&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624016&amp;isnumber=6623991</a><br><br>S.
 Nadi, C. Dietrich, R. Tartler, R. C. Holt and D. Lohmann, "Linux 
variability anomalies: What causes them and how do they get fixed?," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 111-120.<br>doi: 10.1109/MSR.2013.6624017<br>Abstract:
 The Linux kernel is one of the largest configurable open source 
software systems implementing static variability. In Linux, variability 
is scattered over three different artifacts: source code files, Kconfig 
files, and Makefiles. Previous work detected inconsistencies between 
these artifacts that led to anomalies in the intended variability of 
Linux. We call these variability anomalies. However, there has been no 
work done to analyze how these variability anomalies are introduced in 
the first place, and how they get fixed. In this work, we provide an 
analysis of the causes and fixes of variability anomalies in Linux. We 
first perform an exploratory case study that uses an existing set of 
patches which solve variability anomalies to identify patterns for their
 causes. The observations we make from this dataset allow us to develop 
four research questions which we then answer in a confirmatory case 
study on the scope of the whole Linux kernel. We show that variability 
anomalies exist for several releases in the kernel before they get 
fixed, and that contrary to our initial suspicion, typos in feature 
names do not commonly cause these anomalies. Our results show that 
variability anomalies are often introduced through incomplete patches 
that change Kconfig definitions without properly propagating these 
changes to the rest of the system. Anomalies are then commonly fixed 
through changes to the code rather than to Kconfig files.<br> keywords: 
{Linux;program diagnostics;public domain software;KCONFIG files;Linux 
kernel;Linux variability anomalies;Makefiles;configurable open source 
software systems;incomplete patches;source code files;static 
variability;Data mining;Educational institutions;Feature 
extraction;History;Kernel;Linux;GIT;Linux;Mining Software 
Repositories;Software Variability;Variability Anomalies},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624017&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624017&amp;isnumber=6623991</a><br><br>K. Herzig and A. Zeller, "The impact of tangled code changes," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 121-130.<br>doi: 10.1109/MSR.2013.6624018<br>Abstract:
 When interacting with version control systems, developers often commit 
unrelated or loosely related code changes in a single transaction. When 
analyzing the version history, such tangled changes will make all 
changes to all modules appear related, possibly compromising the 
resulting analyses through noise and bias. In an investigation of five 
open-source Java projects, we found up to 15% of all bug fixes to 
consist of multiple tangled changes. Using a multi-predictor approach to
 untangle changes, we show that on average at least 16.6% of all source 
files are incorrectly associated with bug reports. We recommend better 
change organization to limit the impact of tangled changes.<br> 
keywords: {Java;configuration management;program debugging;public domain
 software;bug fixes;bug reports;change organization;multiple tangled 
changes;multipredictor approach;open-source JAVA projects;source 
files;version control systems;Accuracy;History;Manuals;Noise;Open source
 software;Partitioning algorithms;Mining software repositories;bias;data
 quality;noise;tangled code changes},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624018&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624018&amp;isnumber=6623991</a><br><br>B.
 Dit, A. Holtzhauer, D. Poshyvanyk and H. Kagdi, "A dataset from change 
history to support evaluation of software maintenance tasks," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 131-134.<br>doi: 10.1109/MSR.2013.6624019<br>Abstract:
 Approaches that support software maintenance need to be evaluated and 
compared against existing ones, in order to demonstrate their usefulness
 in practice. However, oftentimes the lack of well-established sets of 
benchmarks leads to situations where these approaches are evaluated 
using different datasets, which results in biased comparisons. In this 
data paper we describe and make publicly available a set of benchmarks 
from six Java applications, which can be used in the evaluation of 
various software engineering (SE) tasks, such as feature location and 
impact analysis. These datasets consist of textual description of change
 requests, the locations in the source code where they were implemented,
 and execution traces. Four of the benchmarks were already used in 
several SE research papers, and two of them are new. In addition, we 
describe in detail the methodology used for generating these benchmarks 
and provide a suite of tools in order to encourage other researchers to 
validate our datasets and generate new benchmarks for other subject 
software systems. Our online appendix: 
http://www.cs.wm.edu/semeru/data/msr13/.<br> keywords: {Java;software 
maintenance;Java applications;SE tasks;change history;change request 
textual description;feature location;impact analysis;software 
engineering tasks;software maintenance tasks;source code;Benchmark 
testing;Gold;Java;Large scale integration;Software maintenance;Software 
systems;Generate Benchmarks;datasets;feature location;impact analysis},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624019&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624019&amp;isnumber=6623991</a><br><br>A. C. MacLean and C. D. Knutson, "Apache commits: Social network dataset," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 135-138.<br>doi: 10.1109/MSR.2013.6624020<br>Abstract:
 Building non-trivial software is a social endeavor. Therefore, 
understanding the social network of developers is key to the study of 
software development organizations. We present a graph representation of
 the commit behavior of developers within the Apache Software Foundation
 for 2010 and 2011. Relationships between developers in the network 
represent collaborative commit behavior. Several similarity and summary 
metrics have been pre-calculated. The data, along with the tools that 
were used to create it and some further discussion, can be found at: 
http://sequoia.cs.byu.edu/lab/?page=artifacts/apacheGraphs.<br> 
keywords: {graph theory;groupware;software development management;Apache
 Software Foundation;collaborative commit behavior;graph 
representation;similarity metrics;social network dataset;software 
development organizations;summary metrics;Communities;Computer 
languages;Conferences;Measurement;Social network 
services;Software;Vectors},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624020&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624020&amp;isnumber=6623991</a><br><br>R. K. Saha, C. K. Roy, K. A. Schneider and D. E. Perry, "Understanding the evolution of Type-3 clones: An exploratory study," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 139-148.<br>doi: 10.1109/MSR.2013.6624021<br>Abstract:
 Understanding the evolution of clones is important both for 
understanding the maintenance implications of clones and building a 
robust clone management system. To this end, researchers have already 
conducted a number of studies to analyze the evolution of clones, mostly
 focusing on Type-1 and Type-2 clones. However, although there are a 
significant number of Type-3 clones in software systems, we know a 
little how they actually evolve. In this paper, we perform an 
exploratory study on the evolution of Type-1, Type-2, and Type-3 clones 
in six open source software systems written in two different programming
 languages and compare the result with a previous study to better 
understand the evolution of Type-3 clones. Our results show that 
although Type-3 clones are more likely to change inconsistently, the 
absolute number of consistently changed Type-3 clone classes is higher 
than that of Type-1 and Type-2. Type-3 clone classes also have a 
lifespan similar to that of Type-1 and Type-2 clones. In addition, a 
considerable number of Type-1 and Type-2 clones convert into Type-3 
clones during evolution. Therefore, it is important to manage type-3 
clones properly to limit their negative impact. However, various 
automated clone management techniques such as notifying developers about
 clone changes or linked editing should be chosen carefully due to the 
inconsistent nature of Type-3 clones.<br> keywords: {programming 
languages;public domain software;software maintenance;clone maintenance 
implications;open source software systems;programming languages;robust 
clone management system;type-1 clone;type-2 clones;type-3 clone 
evolution;Cloning;History;Maintenance engineering;Robustness;Software 
systems;Syntactics;Type-3 clones;clone evolution;clone genealogy},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624021&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624021&amp;isnumber=6623991</a><br><br>S. Xie, F. Khomh and Y. Zou, "An empirical study of the fault-proneness of clone mutation and clone migration," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 149-158.<br>doi: 10.1109/MSR.2013.6624022<br>Abstract:
 When implementing new features into a software system, developers may 
duplicate several lines of code to reuse some existing code segments. 
This action creates code clones in the software system. The literature 
has documented different types of code clone (e.g., Type-1, Type-2, and 
Type-3). Once created, code clones evolve as they are modified during 
both the development and maintenance phases of the software system. The 
evolution of code clones across the revisions of a software system is 
known as a clone genealogy. Existing work has investigated the 
fault-proneness of Type-1 and Type-2 clone genealogies. In this study, 
we investigate clone genealogies containing Type-3 clones. We analyze 
three long-lived software systems Apache-Ant, ArgoUML, and JBoss, which 
are all written in Java. Using the NiCad clone detection tool, we build 
clone genealogies and examine two evolutionary phenomena on clones: the 
mutation of the type of a clone during the evolution of a system, and 
the migration of clone segments across the repositories of a software 
system. Results show that 1) mutation and migration occur frequently in 
software systems; 2) the mutation of a clone group to Type-2 or Type-3 
clones increases the risk for faults; 3) increasing the distance between
 code segments in a clone group also increases the risk for faults.<br> 
keywords: {software fault tolerance;software 
maintenance;APACHE-ANT;ARGOUML;JAVA;JBOSS;NICAD clone detection 
tool;Type-1 clone genealogy;Type-2 clone genealogy;Type-3 clone 
genealogy;clone migration;clone mutation;clone segment 
reuse;evolutionary phenomena;fault-proneness;long-lived software 
systems;software system development phase;software system maintenance 
phase;software system 
repositories;Cloning;History;Java;Layout;Maintenance 
engineering;Software systems;Types of clones;clone genealogy;clone 
migration;fault-proneness},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624022&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624022&amp;isnumber=6623991</a><br><br>S.
 Gala-Pérez, G. Robles, J. M. González-Barahona and I. Herraiz, 
"Intensive metrics for the study of the evolution of open source 
projects: Case studies from Apache Software Foundation projects," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 159-168.<br>doi: 10.1109/MSR.2013.6624023<br>Abstract:
 Based on the empirical evidence that the ratio of email messages in 
public mailing lists to versioning system commits has remained 
relatively constant along the history of the Apache Software Foundation 
(ASF), this paper has as goal to study what can be inferred from such a 
metric for projects of the ASF. We have found that the metric seems to 
be an intensive metric as it is independent of the size of the project, 
its activity, or the number of developers, and remains relatively 
independent of the technology or functional area of the project. Our 
analysis provides evidence that the metric is related to the technical 
effervescence and popularity of project, and as such can be a good 
candidate to measure its healthy evolution. Other, similar metrics -like
 the ratio of developer messages to commits and the ratio of issue 
tracker messages to commits- are studied for several projects as well, 
in order to see if they have similar characteristics.<br> keywords: 
{electronic mail;mailing systems;project management;software 
metrics;ASF;Apache Software Foundation projects;developer 
message-commits ratio;email messages;healthy evolution;intensive 
metric;issue tracker message-commit ratio;open source project 
evolution;public mailing lists;technical effervescence;versioning 
system},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624023&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624023&amp;isnumber=6623991</a><br><br>A.
 Alali, B. Bartman, C. D. Newman and J. I. Maletic, "A preliminary 
investigation of using age and distance measures in the detection of 
evolutionary couplings," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 169-172.<br>doi: 10.1109/MSR.2013.6624024<br>Abstract:
 An initial study of using two measures to improve the accuracy of 
evolutionary couplings uncovered from version history is presented. Two 
measures, namely the age of a pattern and the distance among items 
within a pattern, are defined and used with the traditional methods for 
computing evolutionary couplings. The goal is to reduce the number of 
false positives (i.e., inaccurate or irrelevant claims of coupling). 
Initial observations are presented that lend evidence that these 
measures may have the potential to improve the results of computing 
evolutionary couplings.<br> keywords: {software maintenance;age 
measures;distance measures;evolutionary coupling detection;item 
distance;pattern age;version history;Couplings;Data 
mining;History;Itemsets;Maintenance engineering;Market 
research;Software;Evolutionary Coupling;Software Repositories},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624024&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624024&amp;isnumber=6623991</a><br><br>M.
 Amoui, N. Kaushik, A. Al-Dabbagh, L. Tahvildari, S. Li and W. Liu, 
"Search-based duplicate defect detection: An industrial experience," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 173-182.<br>doi: 10.1109/MSR.2013.6624025<br>Abstract:
 Duplicate defects put extra overheads on software organizations, as the
 cost and effort of managing duplicate defects are mainly redundant. Due
 to the use of natural language and various ways to describe a defect, 
it is usually hard to investigate duplicate defects automatically. This 
problem is more severe in large software organizations with huge defect 
repositories and massive number of defect reporters. Ideally, an 
efficient tool should prevent duplicate reports from reaching developers
 by automatically detecting and/or filtering duplicates. It also should 
be able to offer defect triagers a list of top-N similar bug reports and
 allow them to compare the similarity of incoming bug reports with the 
suggested duplicates. This demand has motivated us to design and develop
 a search-based duplicate bug detection framework at BlackBerry. The 
approach follows a generalized process model to evaluate and tune the 
performance of the system in a systematic way. We have applied the 
framework on software projects at BlackBerry, in addition to the Mozilla
 defect repository. The experimental results exhibit the performance of 
the developed framework and highlight the high impact of parameter 
tuning on its performance.<br> keywords: {program debugging;project 
management;BlackBerry;Mozilla defect repository;bug reports;duplicate 
detection;duplicate filtering;generalized process model;natural 
language;search-based duplicate bug detection framework;search-based 
duplicate defect detection;software organizations;software 
projects;Electronic mail;Indexing;Noise;Search 
problems;Software;Tuning;Duplicate Defect Detection;Information 
Retrieval;Parameter Tuning;Search-based Software Engineering},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624025&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624025&amp;isnumber=6623991</a><br><br>A. Alipour, A. Hindle and E. Stroulia, "A contextual approach towards more accurate duplicate bug report detection," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 183-192.<br>doi: 10.1109/MSR.2013.6624026<br>Abstract:
 Bug-tracking and issue-tracking systems tend to be populated with bugs,
 issues, or tickets written by a wide variety of bug reporters, with 
different levels of training and knowledge about the system being 
discussed. Many bug reporters lack the skills, vocabulary, knowledge, or
 time to efficiently search the issue tracker for similar issues. As a 
result, issue trackers are often full of duplicate issues and bugs, and 
bug triaging is time consuming and error prone. Many researchers have 
approached the bug-deduplication problem using off-the-shelf 
information-retrieval tools, such as BM25F used by Sun et al. In our 
work, we extend the state of the art by investigating how contextual 
information, relying on our prior knowledge of software quality, 
software architecture, and system-development (LDA) topics, can be 
exploited to improve bug-deduplication. We demonstrate the effectiveness
 of our contextual bug-deduplication method on the bug repository of the
 Android ecosystem. Based on this experience, we conclude that 
researchers should not ignore the context of software engineering when 
using IR tools for deduplication.<br> keywords: {Linux;information 
retrieval;program debugging;software architecture;software 
quality;Android ecosystem;IR tools;LDA topics;bug repository;contextual 
bug-deduplication method;contextual information;duplicate bug report 
detection;information-retrieval tools;software architecture;software 
engineering;software 
quality;system-development;Accuracy;Androids;Computer 
bugs;Context;Humanoid robots;Software;Sun;contextual 
information;deduplication;duplicate bug reports;information 
retrieval;machine learning;textual similarity;triaging},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624026&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624026&amp;isnumber=6623991</a><br><br>S.
 Mani, S. Nagar, D. Mukherjee, R. Narayanam, V. S. Sinha and A. A. 
Nanavati, "Bug resolution catalysts: Identifying essential 
non-committers from bug repositories," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 193-202.<br>doi: 10.1109/MSR.2013.6624027<br>Abstract:
 Bugs are inevitable in software projects. Resolving bugs is the primary
 activity in software maintenance. Developers, who fix bugs through code
 changes, are naturally important participants in bug resolution. 
However, there are other participants in these projects who do not 
perform any code commits. They can be reporters reporting bugs; people 
having a deep technical know-how of the software and providing valuable 
insights on how to solve the bug; bug-tossers who re-assign the bugs to 
the right set of developers. Even though all of them act on the bugs by 
tossing and commenting, not all of them may be crucial for bug 
resolution. In this paper, we formally define essential non-committers 
and try to identify these bug resolution catalysts. We empirically study
 98304 bug reports across 11 open source and 5 commercial software 
projects for validating the existence of such catalysts. We propose a 
network analysis based approach to construct a Minimal Essential Graph 
that identifies such people in a project. Finally, we suggest ways of 
leveraging this information for bug triaging and bug report 
summarization.<br> keywords: {graph theory;professional aspects;program 
debugging;project management;public domain software;software 
maintenance;bug report summarization;bug repositories;bug resolution 
catalysts;bug triaging;bug-tossers;essential noncommitter 
identification;minimal essential graph;network analysis based 
approach;open source;software maintenance;software 
projects;Accuracy;Computer bugs;History;Prediction 
algorithms;Software;Standards;Support vector machines},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624027&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624027&amp;isnumber=6623991</a><br><br>A.
 Lamkanfi, J. Pérez and S. Demeyer, "The Eclipse and Mozilla defect 
tracking dataset: A genuine dataset for mining bug information," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 203-206.<br>doi: 10.1109/MSR.2013.6624028<br>Abstract:
 The analysis of bug reports is an important subfield within the mining 
software repositories community. It explores the rich data available in 
defect tracking systems to uncover interesting and actionable 
information about the bug triaging process. While bug data is readily 
accessible from systems like Bugzilla and JIRA, a common database schema
 and a curated dataset could significantly enhance future research 
because it allows for easier replication. Consequently, in this paper we
 propose the Eclipse and Mozilla Defect Tracking Dataset, a 
representative database of bug data, filtered to contain only genuine 
defects (i.e., no feature requests) and designed to cover the whole 
bug-triage life cycle (i.e., store all intermediate actions). We have 
used this dataset ourselves for predicting bug severity, for studying 
bug-fixing time and for identifying erroneously assigned components. 
Sharing these data with the rest of the community will allow for 
reproducibility, validation and comparison of the results obtained in 
bug-report analyses and experiments.<br> keywords: {data 
mining;information filtering;program debugging;Eclipse;Mozilla;bug data 
database;bug information;bug severity prediction;bug-fixing 
time;bug-report analyses;bug-triage life cycle;data filtering;defect 
tracking dataset;defect tracking systems;erroneously assigned component 
identification;mining software repositories 
community;Communities;Computer bugs;Data 
mining;Databases;Software;Software engineering;XML;Bug 
reports;Dataset;Defect Tracking},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624028&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624028&amp;isnumber=6623991</a><br><br>M. Allamanis and C. Sutton, "Mining source code repositories at massive scale using language modeling," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 207-216.<br>doi: 10.1109/MSR.2013.6624029<br>Abstract:
 The tens of thousands of high-quality open source software projects on 
the Internet raise the exciting possibility of studying software 
development by finding patterns across truly large source code 
repositories. This could enable new tools for developing code, 
encouraging reuse, and navigating large projects. In this paper, we 
build the first giga-token probabilistic language model of source code, 
based on 352 million lines of Java. This is 100 times the scale of the 
pioneering work by Hindle et al. The giga-token model is significantly 
better at the code suggestion task than previous models. More broadly, 
our approach provides a new “lens” for analyzing software projects, 
enabling new complexity metrics based on statistical analysis of large 
corpora. We call these metrics data-driven complexity metrics. We 
propose new metrics that measure the complexity of a code module and the
 topical centrality of a module to a software project. In particular, it
 is possible to distinguish reusable utility classes from classes that 
are part of a program's core logic based solely on general information 
theoretic criteria.<br> keywords: {Java;data mining;project 
management;software management;software metrics;source 
coding;statistical analysis;Java;code module complexity;code suggestion 
task;data-driven complexity metrics;general information theoretic 
criteria;giga-token probabilistic language model;module topical 
centrality;programs core logic;reusable utility classes;software project
 analysis;source code repositories mining;statistical 
analysis;Complexity theory;Entropy;Java;Measurement;Predictive 
models;Software;Training},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624029&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624029&amp;isnumber=6623991</a><br><br>L. B. L. de Souza and M. de Almeida Maia, "Do software categories impact coupling metrics?," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 217-220.<br>doi: 10.1109/MSR.2013.6624030<br>Abstract:
 Software metrics is a valuable mechanism to assess the quality of 
software systems. Metrics can help the automated analysis of the growing
 data available in software repositories. Coupling metrics is a kind of 
software metrics that have been extensively used since the seventies to 
evaluate several software properties related to maintenance, evolution 
and reuse tasks. For example, several works have shown that we can use 
coupling metrics to assess the reusability of software artifacts 
available in repositories. However, thresholds for software metrics to 
indicate adequate coupling levels are still a matter of discussion. In 
this paper, we investigate the impact of software categories on the 
coupling level of software systems. We have found that different 
categories may have different levels of coupling, suggesting that we 
need special attention when comparing software systems in different 
categories and when using predefined thresholds already available in the
 literature.<br> keywords: {software maintenance;software 
metrics;software quality;software reusability;coupling metrics;evolution
 tasks;maintenance tasks;reuse tasks;software artifact 
reusability;software categories;software metrics;software systems 
quality;Business;Couplings;Games;Java;Software;Software 
metrics;Java;Software categories;coupling metrics},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624030&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624030&amp;isnumber=6623991</a><br><br>S. Raemaekers, A. van Deursen and J. Visser, "The Maven repository dataset of metrics, changes, and dependencies," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 221-224.<br>doi: 10.1109/MSR.2013.6624031<br>Abstract:
 We present the Maven Dependency Dataset (MDD), containing metrics, 
changes and dependencies of 148,253 jar files. Metrics and changes have 
been calculated at the level of individual methods, classes and packages
 of multiple library versions. A complete call graph is also presented 
which includes call, inheritance, containment and historical 
relationships between all units of the entire repository. In this paper,
 we describe our dataset and the methodology used to obtain it. We 
present different conceptual views of MDD and we also describe 
limitations and data quality issues that researchers using this data 
should be aware of.<br> keywords: {data mining;software 
libraries;software metrics;software packages;MDD;Maven repository 
dataset;complete call graph;data quality issues;jar file changes;jar 
file dependencies;jar file metrics;library version 
packages;Indexes;Java;Libraries;Measurement;Software;Supercomputers;Data
 mining;Dataset;Maven repository},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624031&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624031&amp;isnumber=6623991</a><br><br>M. Goeminne, M. Claes and T. Mens, "A historical dataset for the Gnome ecosystem," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 225-228.<br>doi: 10.1109/MSR.2013.6624032<br>Abstract:
 We present a dataset of the open source software ecosystem Gnome from a
 social point of view. We have collected historical data about the 
contributors to all Gnome projects stored on git.gnome.org, taking into 
account the problem of identity matching, and associating different 
activity types to the contributors. This type of information is very 
useful to complement the traditional, source-code related information 
one can obtain by mining and analyzing the actual source code. The 
dataset can be obtained at 
https://bitbucket.org/mgoeminne/sgl-flossmetric-dbmerge.<br> keywords: 
{data mining;public domain software;software development 
management;source coding;GNOME ecosystem;GNOME projects;historical 
datasets;open source software ecosystem;source code analysis;source code
 mining;source code related information;Communities;Data 
mining;Databases;Ecosystems;Electronic mail;Merging;Software},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624032&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624032&amp;isnumber=6623991</a><br><br>P. Wagstrom, C. Jergensen and A. Sarma, "A network of Rails a graph dataset of Ruby on Rails and associated projects," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 229-232.<br>doi: 10.1109/MSR.2013.6624033<br>Abstract:
 Software projects, whether open source, proprietary, or a combination 
thereof, rarely exist in isolation. Rather, most projects build on a 
network of people and ideas from dozens, hundreds, or even thousands of 
other projects. Using the GitHub APIs it is possible to extract these 
relationships for millions of users and projects. In this paper we 
present a dataset of a large network of open source projects centered 
around Ruby on Rails. This dataset provides insight into the 
relationships between Ruby on Rails and an ecosystem involving 1116 
projects. To facilitate understanding of this data in the context of 
relationships between projects, users, and their activities, it is 
provided as a graph database suitable for assessing network properties 
of the community and individuals within those communities and can be 
found at https://github.com/pridkett/gitminer-data-rails.<br> keywords: 
{application program interfaces;database management systems;programming 
languages;project management;public domain software;GitHub API;Rail 
network;Ruby on Rails;graph database;graph dataset;network properties 
assessment;open source projects;software 
projects;Communities;Databases;Ecosystems;Electronic 
mail;Rails;Robustness;Software;Data;GitHub;Graph Databases;Ruby on 
Rails},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624033&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624033&amp;isnumber=6623991</a><br><br>G. Gousios, "The GHTorent dataset and tool suite," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 233-236.<br>doi: 10.1109/MSR.2013.6624034<br>Abstract:
 During the last few years, GitHub has emerged as a popular project 
hosting, mirroring and collaboration platform. GitHub provides an 
extensive REST API, which enables researchers to retrieve high-quality, 
interconnected data. The GHTorent project has been collecting data for 
all public projects available on Github for more than a year. In this 
paper, we present the dataset details and construction process and 
outline the challenges and research opportunities emerging from it.<br> 
keywords: {application program interfaces;groupware;information 
resources;information retrieval;software engineering;GHTorent 
dataset;GitHub;collaboration platform;extensive REST API;high-quality 
interconnected data retrieval;hosting platform;mirroring platform;tool 
suite;Collaboration;Data collection;Data 
mining;Databases;History;Organizations;Software 
engineering;GitHub;dataset;repository},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624034&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624034&amp;isnumber=6623991</a><br><br>A. Nistor, T. Jiang and L. Tan, "Discovering, reporting, and fixing performance bugs," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 237-246.<br>doi: 10.1109/MSR.2013.6624035<br>Abstract:
 Software performance is critical for how users perceive the quality of 
software products. Performance bugs - programming errors that cause 
significant performance degradation - lead to poor user experience and 
low system throughput. Designing effective techniques to address 
performance bugs requires a deep understanding of how performance bugs 
are discovered, reported, and fixed. In this paper, we study how 
performance bugs are discovered, reported to developers, and fixed by 
developers, and compare the results with those for non-performance bugs.
 We study performance and non-performance bugs from three popular code 
bases: Eclipse JDT, Eclipse SWT, and Mozilla. First, we find little 
evidence that fixing performance bugs has a higher chance to introduce 
new functional bugs than fixing non-performance bugs, which implies that
 developers may not need to be over-concerned about fixing performance 
bugs. Second, although fixing performance bugs is about as error-prone 
as fixing nonperformance bugs, fixing performance bugs is more difficult
 than fixing non-performance bugs, indicating that developers need 
better tool support for fixing performance bugs and testing performance 
bug patches. Third, unlike many non-performance bugs, a large percentage
 of performance bugs are discovered through code reasoning, not through 
users observing the negative effects of the bugs (e.g., performance 
degradation) or through profiling. The result suggests that techniques 
to help developers reason about performance, better test oracles, and 
better profiling techniques are needed for discovering performance bugs.<br>
 keywords: {program debugging;program testing;reasoning about 
programs;software performance evaluation;software prototyping;software 
quality;Eclipse JDT;Eclipse SWT;Mozilla;code reasoning;nonperformance 
bugs;performance bug discovery;performance bug fixing;performance bug 
patch testing;performance bug reporting;performance bug-programming 
errors;profiling techniques;software performance;software product 
quality;Cognition;Computer 
bugs;Inspection;Manuals;Sociology;Software;Statistics},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624035&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624035&amp;isnumber=6623991</a><br><br>S. Wang, F. Khomh and Y. Zou, "Improving bug localization using correlations in crash reports," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 247-256.<br>doi: 10.1109/MSR.2013.6624036<br>Abstract:
 Nowadays, many software organizations rely on automatic problem 
reporting tools to collect crash reports directly from users' 
environments. These crash reports are later grouped together into crash 
types. Usually, developers prioritize crash types based on the number of
 crash reports and file bugs for the top crash types. Because a bug can 
trigger a crash in different usage scenarios, different crash types are 
sometimes related to a same bug. Two bugs are correlated when the 
occurrence of one bug causes the other bug to occur. We refer to a group
 of crash types related to identical or correlated bugs, as a crash 
correlation group. In this paper, we propose three rules to identify 
correlated crash types automatically. We also propose an algorithm to 
locate and rank buggy files using crash correlation groups. Through an 
empirical study on Firefox and Eclipse, we show that the three rules can
 identify crash correlation groups with a precision of 100% and a recall
 of 90% for Firefox and a precision of 79% and a recall of 65% for 
Eclipse. On the top three buggy file candidates, the proposed bug 
localization algorithm achieves a recall of 62% and a precision of 42% 
for Firefox and a recall of 52% and a precision of 50% for Eclipse. On 
the top 10 buggy file candidates, the recall increases to 92% for 
Firefox and 90% for Eclipse. Developers can combine the proposed crash 
correlation rules with the new bug localization algorithm to identify 
and fix correlated crash types all together.<br> keywords: {program 
debugging;Eclipse;Firefox;automatic problem reporting tools;bug 
localization algorithm;buggy files;correlated bugs;crash report 
correlations;crash types;software organizations;Computer 
bugs;Correlation;Educational 
institutions;Organizations;Servers;Software;Automatic Problem Reporting 
Tools;Bug Correlation;Bug Localization;Crash Reports;Crashes;Stack 
Traces},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624036&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624036&amp;isnumber=6623991</a><br><br>S.
 Raemaekers, G. F. Nane, A. van Deursen and J. Visser, "Testing 
principles, current practices, and effects of change localization," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 257-266.<br>doi: 10.1109/MSR.2013.6624037<br>Abstract:
 Best practices in software development state that code that is likely 
to change should be encapsulated to localize possible modifications. In 
this paper, we investigate the application and effects of this design 
principle. We investigate the relationship between the stability, 
encapsulation and popularity of libraries on a dataset of 148,253 Java 
libraries. We find that bigger systems with more rework in existing 
methods have less stable interfaces and that bigger systems tend to 
encapsulate dependencies better. Additionally, there are a number of 
factors that are associated with change in library interfaces, such as 
rework in existing methods, system size, encapsulation of dependencies 
and the number of dependencies. We find that current encapsulation 
practices are not targeted at libraries that change the most. We also 
investigate the strength of ripple effects caused by instability of 
dependencies and we find that libraries cause ripple effects in systems 
using them and that these effects can be mitigated by encapsulation.<br>
 keywords: {Java;data encapsulation;program testing;software 
libraries;Java libraries;change localization;design 
principle;encapsulation practices;less stable interfaces;library 
interfaces;ripple effects;software development;testing 
principles;Correlation;Encapsulation;Java;Libraries;Measurement;Software;Stability
 analysis;Software libraries;encapsulation;ripple effects},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624037&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624037&amp;isnumber=6623991</a><br><br>K.
 Dullemond, B. van Gameren, M. A. Storey and A. van Deursen, "Fixing the
 ‘Out of sight out of mind’ problem one year of mood-based microblogging
 in a distributed software team," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 267-276.<br>doi: 10.1109/MSR.2013.6624038<br>Abstract:
 Distributed teams face the challenge of staying connected. How do team 
members stay connected when they no longer see each other on a daily 
basis? What should be done when there is no coffee corner to share your 
latest exploits? In this paper we evaluate a microblogging system which 
makes this possible in a distributed setting. The system, WeHomer, 
enables the sharing of information and corresponding emotions in a fully
 distributed organization. We analyzed the content of over a year of 
usage data by 19 team members in a structured fashion, performed 5 
semi-structured interviews and report our findings in this paper. We 
draw conclusions about the topics shared, the impact on software teams 
and the impact of distribution and team composition. Main findings 
include an increase in team-connectedness and easier access to 
information that is traditionally harder to consistently acquire.<br> 
keywords: {Web sites;organisational aspects;software development 
management;team working;WeHomer;coffee corner;distributed 
setting;distributed software team;fully distributed 
organization;information sharing;mood-based 
microblogging;out-of-sight-out-of-mind problem;semistructured 
interviews;team composition;team 
members;Companies;Encoding;Media;Mood;Software;Software 
engineering;Twitter},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624038&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624038&amp;isnumber=6623991</a><br><br>A.
 Guzzi, A. Bacchelli, M. Lanza, M. Pinzger and A. van Deursen, 
"Communication in open source software development mailing lists," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 277-286.<br>doi: 10.1109/MSR.2013.6624039<br>Abstract:
 Open source software (OSS) development teams use electronic means, such
 as emails, instant messaging, or forums, to conduct open and public 
discussions. Researchers investigated mailing lists considering them as a
 hub for project communication. Prior work focused on specific aspects 
of emails, for example the handling of patches, traceability concerns, 
or social networks. This led to insights pertaining to the investigated 
aspects, but not to a comprehensive view of what developers communicate 
about. Our objective is to increase the understanding of development 
mailing lists communication. We quantitatively and qualitatively 
analyzed a sample of 506 email threads from the development mailing list
 of a major OSS project, Lucene. Our investigation reveals that 
implementation details are discussed only in about 35% of the threads, 
and that a range of other topics is discussed. Moreover, core developers
 participate in less than 75% of the threads. We observed that the 
development mailing list is not the main player in OSS project 
communication, as it also includes other channels such as the issue 
repository.<br> keywords: {project management;public domain 
software;software engineering;software management;Lucene;OSS project 
communication;development mailing lists communication;email threads;open
 source software development mailing lists;Buildings;Data 
mining;Electronic mail;Linux;Software;Sorting},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624039&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624039&amp;isnumber=6623991</a><br><br>X. Xia, D. Lo, X. Wang and B. Zhou, "Tag recommendation in software information sites," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 287-296.<br>doi: 10.1109/MSR.2013.6624040<br>Abstract:
 Nowadays, software engineers use a variety of online media to search 
and become informed of new and interesting technologies, and to learn 
from and help one another. We refer to these kinds of online media which
 help software engineers improve their performance in software 
development, maintenance and test processes as software information 
sites. It is common to see tags in software information sites and many 
sites allow users to tag various objects with their own words. Users 
increasingly use tags to describe the most important features of their 
posted contents or projects. In this paper, we propose TagCombine, an 
automatic tag recommendation method which analyzes objects in software 
information sites. TagCombine has 3 different components: 1. multilabel 
ranking component which considers tag recommendation as a multi-label 
learning problem; 2. similarity based ranking component which recommends
 tags from similar objects; 3. tag-term based ranking component which 
considers the relationship between different terms and tags, and 
recommends tags after analyzing the terms in the objects. We evaluate 
TagCombine on 2 software information sites, StackOverflow and Freecode, 
which contain 47,668 and 39,231 text documents, respectively, and 437 
and 243 tags, respectively. Experiment results show that for 
StackOverflow, our TagCombine achieves recall@5 and recall@10 scores of 
0.5964 and 0.7239, respectively; For Freecode, it achieves recall@5 and 
recall@10 scores of 0.6391 and 0.7773, respectively. Moreover, averaging
 over StackOverflow and Freecode results, we improve TagRec proposed by 
Al-Kofahi et al. by 22.65% and 14.95%, and the tag recommendation method
 proposed by Zangerle et al. by 18.5% and 7.35% for recall@5 and 
recall@10 scores.<br> keywords: {learning (artificial 
intelligence);program testing;recommender systems;social networking 
(online);software maintenance;text 
analysis;Freecode;StackOverflow;TagCombine;TagRec;automatic tag 
recommendation method;multilabel learning problem;multilabel ranking 
component;online media;similarity based ranking component;software 
development;software engineers;software information sites;software 
maintenance;software test processes;tag-term based ranking 
component;text documents;Educational institutions;Media;Prediction 
algorithms;Search problems;Software;Software algorithms;Vectors;Online 
Media;Software Information Sites;Tag Recommendation;TagCombine},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624040&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624040&amp;isnumber=6623991</a><br><br>R. Robbes and D. Röthlisberger, "Using developer interaction data to compare expertise metrics," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 297-300.<br>doi: 10.1109/MSR.2013.6624041<br>Abstract:
 The expertise of a software developer is said to be a crucial factor 
for the development time required to complete a task. Even if this 
hypothesis is intuitive, research has not yet quantified the effect of 
developer expertise on development time. A related problem is that the 
design space for expertise metrics is large; out of the various 
automated expertise metrics proposed, we do not know which metric most 
reliably captures expertise. What prevents a proper evaluation of 
expertise metrics and their relation with development time is the lack 
of data on development tasks, such as their precise duration. 
Fortunately, this data is starting to become available in the form of 
growing developer interaction repositories. We show that applying MSR 
techniques to these developer interaction repositories gives us the 
necessary tools to perform such an evaluation.<br> keywords: 
{professional aspects;software metrics;MSR techniques;design 
space;expertise metrics;software developer interaction 
repositories;software development time;Computer 
science;Correlation;History;Productivity;Software;Time measurement},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624041&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624041&amp;isnumber=6623991</a><br><br>M. Squire, "Project roles in the Apache Software Foundation: A dataset," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 301-304.<br>doi: 10.1109/MSR.2013.6624042<br>Abstract:
 This paper outlines the steps in the creation and maintenance of a new 
dataset listing leaders of the various projects of the Apache Software 
Foundation (ASF). Included in this dataset are different levels of 
committers to the various ASF project code bases, as well as regular and
 emeritus members of the ASF, and directors and officers of the ASF. The
 dataset has been donated to the FLOSSmole project under an open source 
license, and is available for download 
(https://code.google.com/p/flossmole/downloads/detail?name=apachePeople2013-Jan.zip),
 or for direct querying via a database client.<br> keywords: {project 
management;public domain software;software management;ASF project code 
base;Apache Software Foundation;FLOSSmole project;free-libre-open source
 software;project roles;Databases;Electronic 
mail;Minutes;Organizations;Software;Web pages;Apache;dataset;email;free 
software;hierarchy;leadership;open source;project organization;roles},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624042&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624042&amp;isnumber=6623991</a><br><br>M. Squire, "Apache-affiliated Twitter screen names: A dataset," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 305-308.<br>doi: 10.1109/MSR.2013.6624043<br>Abstract:
 This paper describes a new dataset containing Twitter screen names for 
members of the projects affiliated with the Apache Software Foundation 
(ASF). The dataset includes the confirmed Twitter screen names, as well 
as the real name as listed on Twitter, and the user identification as 
used within the Apache organization. The paper also describes the 
process used to collect and clean this data, and shows some sample 
queries for learning how to use the data. The dataset has been donated 
to the FLOSSmole project and is available for download 
(https://code.google.com/p/flossmole/downloads/detail?name=apacheTwitter20
 13-Jan.zip) or direct querying via a database client.<br> keywords: 
{data handling;query processing;social networking (online);ASF;Apache 
Software Foundation;Apache-affiliated Twitter screen names;FLOSSmole 
project;direct querying;user identification;Data 
mining;Databases;Electronic mail;Manuals;Software;Twitter;Web 
sites;Apache;Twitter;committer;dataset;follower;free 
software;identification;names;open source software;screen name;user 
name},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624043&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624043&amp;isnumber=6623991</a><br><br>B. Sisman and A. C. Kak, "Assisting code search with automatic Query Reformulation for bug localization," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 309-318.<br>doi: 10.1109/MSR.2013.6624044<br>Abstract:
 Source code retrieval plays an important role in many software 
engineering tasks. However, designing a query that can accurately 
retrieve the relevant software artifacts can be challenging for 
developers as it requires a certain level of knowledge and experience 
regarding the code base. This paper demonstrates how the difficulty of 
designing a proper query can be alleviated through automatic Query 
Reformulation (QR) - an under-the-hood operation for reformulating a 
user's query with no additional input from the user. The proposed QR 
framework works by enriching a user's search query with certain specific
 additional terms drawn from the highest-ranked artifacts retrieved in 
response to the initial query. The important point here is that these 
additional terms injected into a query are those that are deemed to be 
“close” to the original query terms in the source code on the basis of 
positional proximity. This similarity metric is based on the notion that
 terms that deal with the same concepts in source code are usually 
proximal to one another in the same files. We demonstrate the 
superiority of our QR framework in relation to the QR frameworks 
well-known in the natural language document retrieval by showing 
significant improvements in bug localization performance for two large 
software projects using more than 4,000 queries.<br> keywords: {document
 handling;program debugging;query processing;software metrics;automatic 
QR;automatic query reformulation;bug localization performance 
improvement;code base;code search;highest-ranked artifact 
retrieval;initial query;natural language document retrieval;positional 
proximity;query design;similarity metric;software artifact 
retrieval;software engineering tasks;software projects;source code 
retrieval;under-the-hood operation;user search 
query;Animation;Context;Measurement;Search engines;Software;Software 
libraries;Strips;Bug Localization;Pseudo Relevance Feedback;Query 
Expansion;Query Reformulation;Software Maintenance},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624044&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624044&amp;isnumber=6623991</a><br><br>J.
 Wang, Y. Dang, H. Zhang, K. Chen, T. Xie and D. Zhang, "Mining succinct
 and high-coverage API usage patterns from source code," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 319-328.<br>doi: 10.1109/MSR.2013.6624045<br>Abstract:
 During software development, a developer often needs to discover 
specific usage patterns of Application Programming Interface (API) 
methods. However, these usage patterns are often not well documented. To
 help developers to get such usage patterns, there are approaches 
proposed to mine client code of the API methods. However, they lack 
metrics to measure the quality of the mined usage patterns, and the API 
usage patterns mined by the existing approaches tend to be many and 
redundant, posing significant barriers for being practical adoption. To 
address these issues, in this paper, we propose two quality metrics 
(succinctness and coverage) for mined usage patterns, and further 
propose a novel approach called Usage Pattern Miner (UP-Miner) that 
mines succinct and high-coverage usage patterns of API methods from 
source code. We have evaluated our approach on a large-scale Microsoft 
codebase. The results show that our approach is effective and 
outperforms an existing representative approach MAPO. The user studies 
conducted with Microsoft developers confirm the usefulness of the 
proposed approach in practice.<br> keywords: {application program 
interfaces;data mining;software reusability;MAPO;UP-miner;application 
programming interface;client code mining;high-coverage API usage pattern
 mining;large-scale Microsoft codebase;software development;software 
reuse;source code;succinct API usage pattern mining;usage pattern 
discovery;usage pattern miner;Clustering algorithms;Context;Data 
mining;Indexes;Measurement;Probabilistic logic;Redundancy;API 
usage;mining software repositories;sequence mining;software reuse;usage 
pattern},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624045&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624045&amp;isnumber=6623991</a><br><br>W. M. Khoo, A. Mycroft and R. Anderson, "Rendezvous: A search engine for binary code," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 329-338.<br>doi: 10.1109/MSR.2013.6624046<br>Abstract:
 The problem of matching between binaries is important for software 
copyright enforcement as well as for identifying disclosed 
vulnerabilities in software. We present a search engine prototype called
 Rendezvous which enables indexing and searching for code in binary 
form. Rendezvous identifies binary code using a statistical model 
comprising instruction mnemonics, control flow sub-graphs and data 
constants which are simple to extract from a disassembly, yet 
normalising with respect to different compilers and optimisations. 
Experiments show that Rendezvous achieves F<sub>2</sub> measures of 
86.7% and 83.0% on the GNU C library compiled with different compiler 
optimisations and the GNU coreutils suite compiled with gcc and clang 
respectively. These two code bases together comprise more than one 
million lines of code. Rendezvous will bring significant changes to the 
way patch management and copyright enforcement is currently performed.<br> keywords: {copyright;optimising compilers;search engines;software reusability;statistical analysis;F<sub>2</sub>
 measures;GNU C library;GNU coreutils suite;binary code search 
engine;clang;code bases;compiler optimisations;control flow 
subgraphs;gcc;instruction mnemonics;rendezvous;search engine 
prototype;software copyright enforcement;statistical 
model;Accuracy;Binary codes;Indexing;Libraries;Optimization;Search 
engines},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624046&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624046&amp;isnumber=6623991</a><br><br>W. Janjic, O. Hummel, M. Schumacher and C. Atkinson, "An unabridged source code dataset for research in software reuse," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 339-342.<br>doi: 10.1109/MSR.2013.6624047<br>Abstract:
 This paper describes a large, unabridged data-set of Java source code 
gathered and shared as part of the Merobase Component Finder project of 
the Software-Engineering Group at the University of Mannheim. It 
consists of the complete index used to drive the search engine, 
www.merobase.com, the vast majority<sup>1</sup> of the source code 
modules accessible through it, and a tool that enables researchers to 
efficiently browse the collected data. We describe the techniques used 
to collect, format and store the data set, as well as the core 
capabilities of the Merobase search engine such as classic 
keyword-based, interface-based and test-driven search. This data-set, 
which represents one of the largest searchable collections of source and
 binary modules available online, has been recently made available for 
download and use in further research projects. All files are available 
at http://merobase.informatik.uni-mannheim.de/sources/.<br> keywords: 
{Java;search engines;software reusability;source coding;Java source 
code;Merobase component finder project;Merobase search engine;University
 of Mannheim;binary modules;interface-based search;keyword-based 
search;software engineering group;software reuse;source code 
modules;test-driven search;unabridged source code 
dataset;Containers;Indexes;Java;Open source software;Relational 
databases;Search engines},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624047&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624047&amp;isnumber=6623991</a><br><br>H. Hemmati <em>et al</em>., "The MSR Cookbook: Mining a decade of research," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 343-352.<br>doi: 10.1109/MSR.2013.6624048<br>Abstract:
 The Mining Software Repositories (MSR) research community has grown 
significantly since the first MSR workshop was held in 2004. As the 
community continues to broaden its scope and deepens its expertise, it 
is worthwhile to reflect on the best practices that our community has 
developed over the past decade of research. We identify these best 
practices by surveying past MSR conferences and workshops. To that end, 
we review all 117 full papers published in the MSR proceedings between 
2004 and 2012. We extract 268 comments from these papers, and categorize
 them using a grounded theory methodology. From this evaluation, four 
high-level themes were identified: data acquisition and preparation, 
synthesis, analysis, and sharing/replication. Within each theme we 
identify several common recommendations, and also examine how these 
recommendations have evolved over the past decade. In an effort to make 
this survey a living artifact, we also provide a public forum that 
contains the extracted recommendations in the hopes that the MSR 
community can engage in a continuing discussion on our evolving best 
practices.<br> keywords: {data acquisition;data analysis;data 
mining;recommender systems;MSR cookbook;Mining Software Repositories 
research community;data acquisition;data analysis;data preparation;data 
replication;data sharing;data synthesis;grounded theory 
methodology;recommendation;Best practices;Communities;Context;Data 
acquisition;Data mining;Electronic mail;Software},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624048&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624048&amp;isnumber=6623991</a><br><br>S. Demeyer, A. Murgia, K. Wyckmans and A. Lamkanfi, "Happy Birthday! A trend analysis on past MSR papers," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 353-362.<br>doi: 10.1109/MSR.2013.6624049<br>Abstract:
 On the occasion of the 10th anniversary of the MSR conference, it is a 
worthwhile exercise to meditate on the past, present and future of our 
research discipline. Indeed, since the MSR community has experienced a 
big influx of researchers bringing in new ideas, state-of-the art 
technology and contemporary research methods it is unclear what the 
future might bring. In this paper, we report on a text mining exercise 
applied on the complete corpus of MSR papers to reflect on where we come
 from; where we are now; and where we should be going. We address issues
 like the trendy (and outdated) research topics; the frequently (and 
less frequently) cited cases; the popular (and emerging) mining 
infrastructure; and finally the proclaimed actionable information which 
we are deemed to uncover.<br> keywords: {data mining;software 
engineering;software management;text analysis;MSR conference;MSR 
papers;mining infrastructure;mining software repositories;research 
topics;text mining exercise;trend analysis;Communities;Computer 
bugs;Databases;Market research;Software;Text mining},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624049&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624049&amp;isnumber=6623991</a><br><br>G. Ghezzi and H. C. Gall, "Replicating mining studies with SOFAS," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 363-372.<br>doi: 10.1109/MSR.2013.6624050<br>Abstract:
 The replication of studies in mining software repositories (MSR) is 
essential to compare different mining techniques or assess their 
findings across many projects. However, it has been shown that very few 
of these studies can be easily replicated. Their replication is just as 
fundamental as the studies themselves and is one of the main threats to 
validity that they suffer from. In this paper, we show how we can 
alleviate this problem with our SOFAS framework. SOFAS is a platform 
that enables a systematic and repeatable analysis of software projects 
by providing extensible and composable analysis workflows. These 
workflows can be applied on a multitude of software projects, 
facilitating the replication and scaling of mining studies. In this 
paper, we show how and to which degree replication can be achieved. We 
investigated the mining studies of MSR from 2004 to 2011 and found that 
from 88 studies published in the MSR proceedings so far, we can fully 
replicate 25 empirical studies. Additionally, we can replicate 27 
additional studies to a large extent. These studies account for 30% and 
32%, respectively, of the mining studies published. To support our claim
 we describe in detail one large study that we replicated and discuss 
how replication with SOFAS works for the other studies investigated. To 
discuss the potential of our platform we also characterise how studies 
can be easily enriched to deliver even more comprehensive answers by 
extending the analysis workflows provided by the platform.<br> keywords:
 {data mining;project management;software architecture;MSR;SOFAS 
framework;composable analysis workflows;extensible analysis 
workflows;mining software repositories;mining study 
replication;repeatable software project analysis;systematic software 
project analysis;Catalogs;Data mining;History;Ontologies;Standards;Web 
services},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624050&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624050&amp;isnumber=6623991</a><br><br>B. Vasilescu, A. Serebrenik and T. Mens, "A historical dataset of software engineering conferences," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 373-376.<br>doi: 10.1109/MSR.2013.6624051<br>Abstract:
 The Mining Software Repositories community typically focuses on data 
from software configuration management tools, mailing lists, and bug 
tracking repositories to uncover interesting and actionable information 
about the evolution of software systems. However, the techniques 
employed and the challenges faced when mining are not restricted to 
these types of repositories. In this paper, we present an atypical 
dataset of software engineering conferences, containing historical data 
about the accepted papers and the composition of programme committees 
for eleven well-established conferences. The dataset (published on 
Github at https://github.com/tue-mdse/conferenceMetrics) can be used, 
e.g., by conference steering committees or programme committee chairs to
 assess their selection process and compare against other conferences in
 the field, or by prospective authors to decide in which conferences to 
publish.<br> keywords: {data analysis;data 
mining;history;publishing;software engineering;Mining Software 
Repositories community;atypical dataset;conference steering 
committees;dataset mining;historical data;programme committee 
chairs;software engineering conferences;Communities;Conferences;Data 
mining;Databases;Merging;Software;Software engineering},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624051&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624051&amp;isnumber=6623991</a><br><br>M.
 J. Howard, S. Gupta, L. Pollock and K. Vijay-Shanker, "Automatically 
mining software-based, semantically-similar words from comment-code 
mappings," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 377-386.<br>doi: 10.1109/MSR.2013.6624052<br>Abstract:
 Many software development and maintenance tools involve matching 
between natural language words in different software artifacts (e.g., 
traceability) or between queries submitted by a user and software 
artifacts (e.g., code search). Because different people likely created 
the queries and various artifacts, the effectiveness of these tools is 
often improved by expanding queries and adding related words to textual 
artifact representations. Synonyms are particularly useful to overcome 
the mismatch in vocabularies, as well as other word relations that 
indicate semantic similarity. However, experience shows that many words 
are semantically similar in computer science situations, but not in 
typical natural language documents. In this paper, we present an 
automatic technique to mine semantically similar words, particularly in 
the software context. We leverage the role of leading comments for 
methods and programmer conventions in writing them. Our evaluation of 
our mined related comment-code word mappings that do not already occur 
in WordNet are indeed viewed as computer science, semantically-similar 
word pairs in high proportions.<br> keywords: {data mining;natural 
language processing;software maintenance;software tools;text 
analysis;WordNet;automatic mining software-based semantically-similar 
word mining;comment-code word mapping;computer science;natural language 
documents;natural language words;software artifacts;software development
 tools;software maintenance tools;software traceability;synonyms;textual
 artifact representation;vocabulary mismatch;Computer 
science;Context;Data mining;Maintenance 
engineering;Semantics;Software;Tagging},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624052&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624052&amp;isnumber=6623991</a><br><br>M.
 Greiler, A. Zaidman, A. van Deursen and M. A. Storey, "Strategies for 
avoiding text fixture smells during software evolution," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 387-396.<br>doi: 10.1109/MSR.2013.6624053<br>Abstract:
 An important challenge in creating automated tests is how to design 
test fixtures, i.e., the setup code that initializes the system under 
test before actual automated testing can start. Test designers have to 
choose between different approaches for the setup, trading off 
maintenance overhead with slow test execution. Over time, test code 
quality can erode and test smells can develop, such as the occurrence of
 overly general fixtures, obscure inline code and dead fields. In this 
paper, we investigate how fixture-related test smells evolve over time 
by analyzing several thousand revisions of five open source systems. Our
 findings indicate that setup management strategies strongly influence 
the types of test fixture smells that emerge in code, and that several 
types of fixture smells often emerge at the same time. Based on this 
information, we recommend important guidelines for setup strategies, and
 suggest how tool support can be improved to help in both avoiding the 
emergence of such smells as well as how to refactor code when test 
smells do appear.<br> keywords: {configuration management;program 
testing;public domain software;software maintenance;automated 
testing;automated tests;code refactoring;fixture-related test 
smells;open source systems;setup code;setup management 
strategies;software evolution;test code quality;text fixture smell 
avoidance;Dispersion;Fixtures;Java;Market research;Software 
systems;Testing;maintenance;test evolution;test fixture smells},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624053&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624053&amp;isnumber=6623991</a><br><br>Q.
 Fu, J. G. Lou, Q. Lin, R. Ding, D. Zhang and T. Xie, "Contextual 
analysis of program logs for understanding system behaviors," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 397-400.<br>doi: 10.1109/MSR.2013.6624054<br>Abstract:
 Understanding the behaviors of a software system is very important for 
performing daily system maintenance tasks. In practice, one way to gain 
knowledge about the runtime behavior of a system is to manually analyze 
system logs collected during the system executions. With the increasing 
scale and complexity of software systems, it has become challenging for 
system operators to manually analyze system logs. To address these 
challenges, in this paper, we propose a new approach for contextual 
analysis of system logs for understanding a system's behaviors. In 
particular, we first use execution patterns to represent execution 
structures reflected by a sequence of system logs, and propose an 
algorithm to mine execution patterns from the program logs. The mined 
execution patterns correspond to different execution paths of the 
system. Based on these execution patterns, our approach further learns 
essential contextual factors (e.g., the occurrences of specific program 
logs with specific parameter values) that cause a specific branch or 
path to be executed by the system. The mining and learning results can 
help system operators to understand a software system's runtime 
execution logic and behaviors during various tasks such as system 
problem diagnosis. We demonstrate the feasibility of our approach upon 
two real-world software systems (Hadoop and Ethereal).<br> keywords: 
{data mining;program diagnostics;software 
maintenance;Ethereal;Hadoop;execution pattern mining;execution 
patterns;execution structure representation;program log contextual 
analysis;software system behavior understanding;software system runtime 
execution logic;system maintenance tasks;system problem 
diagnosis;Accuracy;Decision trees;Feature 
extraction;Indexes;Lattices;Runtime;Software systems;Contextual 
Analysis;log analysis;understanding system behaviors},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624054&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624054&amp;isnumber=6623991</a><br><br>D. Binkley, D. Lawrie, L. Pollock, E. Hill and K. Vijay-Shanker, "A dataset for evaluating identifier splitters," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 401-404.<br>doi: 10.1109/MSR.2013.6624055<br>Abstract:
 Software engineering and evolution techniques have recently started to 
exploit the natural language information in source code. A key step in 
doing so is splitting identifiers into their constituent words. While 
simple in concept, identifier splitting raises several challenging 
issues, leading to a range of splitting techniques. Consequently, the 
research community would benefit from a dataset (i.e., a gold set) that 
facilitates comparative studies of identifier splitting techniques. A 
gold set of 2,663 split identifiers was constructed from 8,522 
individual human splitting judgements and can be obtained from 
www.cs.loyola.edu/~binkley/ludiso. This set's construction and 
observations aimed at its effective use are described.<br> keywords: 
{computational linguistics;program interpreters;software 
engineering;source coding;constituent words;human splitting 
judgements;identifier splitter evaluation dataset;identifier splitting 
techniques;natural language information;software engineering;software 
evolution techniques;source code;Data mining;Educational 
institutions;Gold;Java;Software;Speech recognition},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624055&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624055&amp;isnumber=6623991</a><br><br>S. Butler, M. Wermelinger, Y. Yu and H. Sharp, "INVocD: Identifier name vocabulary dataset," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 405-408.<br>doi: 10.1109/MSR.2013.6624056<br>Abstract:
 INVocD is a database of the identifier name declarations and vocabulary
 found in 60 FLOSS Java projects where the source code structure is 
recorded and the identifier name vocabulary is made directly available, 
offering advantages for identifier name research over conventional 
source code models. The database has been used to support a range of 
research projects from identifier name analysis to concept location, and
 provides many opportunities to researchers. INVocD may be downloaded 
from http://oro.open.ac.uk/36992.<br> keywords: {Java;software 
engineering;source coding;FLOSS Java projects;INVocD;concept 
location;identifier name analysis;identifier name 
declarations;identifier name vocabulary dataset;source code 
models;source code structure;Arrays;Indexes;Java;Support vector 
machines;Vocabulary;identifier names;source code mining;source code 
model},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624056&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624056&amp;isnumber=6623991</a><br><br>F. Peters, T. Menzies and A. Marcus, "Better cross company defect prediction," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 409-418.<br>doi: 10.1109/MSR.2013.6624057<br>Abstract:
 How can we find data for quality prediction? Early in the life cycle, 
projects may lack the data needed to build such predictors. Prior work 
assumed that relevant training data was found nearest to the local 
project. But is this the best approach? This paper introduces the Peters
 filter which is based on the following conjecture: When local data is 
scarce, more information exists in other projects. Accordingly, this 
filter selects training data via the structure of other projects. To 
assess the performance of the Peters filter, we compare it with two 
other approaches for quality prediction. Within-company learning and 
cross-company learning with the Burak filter (the state-of-the-art 
relevancy filter). This paper finds that: 1) within-company predictors 
are weak for small data-sets; 2) the Peters filter+cross-company builds 
better predictors than both within-company and the Burak 
filter+cross-company; and 3) the Peters filter builds 64% more useful 
predictors than both within-company and the Burak filter+cross-company 
approaches. Hence, we recommend the Peters filter for cross-company 
learning.<br> keywords: {data mining;learning (artificial 
intelligence);software quality;Burak filter-cross-company 
approach;Peters filter-cross-company approach;cross-company defect 
prediction;cross-company learning;local data;quality 
prediction;state-of-the-art relevancy filter;training 
data;within-company learning;within-company 
predictors;Companies;Estimation;Predictive models;Radio 
frequency;Software;Training data;Vegetation;Cross company;data 
mining;defect prediction},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624057&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624057&amp;isnumber=6623991</a><br><br>W. Hu and K. Wong, "Using citation influence to predict software defects," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 419-428.<br>doi: 10.1109/MSR.2013.6624058<br>Abstract:
 The software dependency network reflects structure and the developer 
contribution network reflects process. Previous studies have used social
 network properties over these networks to predict whether a software 
component is defect-prone. However, these studies do not consider the 
strengths of the dependencies in the networks. In our approach, we use a
 citation influence topic model to determine dependency strengths among 
components and developers, analyze weak and strong dependencies 
separately, and apply social network properties to predict defect-prone 
components. In experiments on Eclipse and NetBeans, our approach has 
higher accuracy than prior work.<br> keywords: {citation 
analysis;program debugging;program diagnostics;program testing;software 
fault tolerance;Eclipse;NetBeans;citation influence topic 
model;defect-prone software component prediction;dependency 
strengths;developer contribution network;social network 
properties;software defect prediction;software dependency 
network;Accuracy;Couplings;Predictive models;Social network 
services;Software;Software measurement},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624058&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624058&amp;isnumber=6623991</a><br><br>M.
 Tsunoda, Y. Kamei, K. Toda, M. Nagappan, K. Fushida and N. Ubayashi, 
"Revisiting software development effort estimation based on early phase 
development activities," <em>Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on</em>, San Francisco, CA, 2013, pp. 429-438.<br>doi: 10.1109/MSR.2013.6624059<br>Abstract:
 Many research projects on software estimation use software size as a 
major explanatory variable. However, practitioners sometimes use the 
ratio of effort for early phase activities such as planning and 
requirement analysis, to the effort for the whole development phase of 
the software in order to estimate effort. In this paper, we focus on 
effort estimation based on the effort for early phase activities. The 
goal of the research is to examine the relationship of early phase 
effort and software size with software development effort. To achieve 
the goal, we built effort estimation models using early phase effort as 
an explanatory variable, and compared the estimation accuracies of these
 models to the effort estimation models based on software size. In 
addition, we built estimation models using both early phase effort and 
software size. In our experiment, we used ISBSG dataset, which was 
collected from software development companies, and regarded planning 
phase effort and requirement analysis effort as early phase effort. The 
result of the experiment showed that when both software size and sum of 
planning and requirement analysis phase effort were used as explanatory 
variables, the estimation accuracy was most improved (Average Balanced 
Relative Error was improved to 75.4% from 148.4%). Based on the result, 
we recommend that both early phase effort and software size be used as 
explanatory variables, because that combination showed the high 
accuracy, and did not have multicollinearity issues.<br> keywords: 
{software development management;systems analysis;ISBSG dataset;early 
phase development activities;early phase effort;planning phase 
effort;requirement analysis effort;software development 
companies;software development effort estimation;software 
estimation;software size;Accuracy;Estimation;Linear 
regression;Mathematical model;Planning;Productivity;Software;Effort 
prediction;early phase effort;estimation accuracy;function point;linear 
regression analysis},<br>URL:&nbsp;<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624059&amp;isnumber=6623991">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6624059&amp;isnumber=6623991</a><br><br>
</body></html>